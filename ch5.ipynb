{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dohy-Lee/NLP_By_Pytorch/blob/main/ch5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CddntUN4dt2K"
      },
      "source": [
        "* 임베딩과 표현학습 : 이산 타입과 벡터 공간의 포인트 사이에 매핑을 학습하는 것  \n",
        "* 단어 임베딩 : 이산 타입이 단어일 때 밀집 벡터 표현  \n",
        "* 임베딩 방법에는 <u>TF-IDF와 같은 카운터 기반의 임베딩 방법</u>, <u>학습 기반 혹은 예측 기반의 임베딩 방법</u>이 있음.\n",
        "* 저차원으로 학습된 밀집 표현의 장점 (원-핫 벡터와 카운터 기반의 벡터와 비교)\n",
        "  * 차원을 줄이면 계산을 효율적으로 수행\n",
        "  * 카운트 기반 표현은 여러 차원에 비슷한 정보를 중복해 인코딩한 고차원 벡터를 만듦.  \n",
        "  → 이러한 벡터는 통계적 장점을 공유하지 못함\n",
        "  * 고차원 입력은 머신러닝과 최적화에서 실제로 문제가 될 수 있음 (차원의 저주)  \n",
        "전통적으로 이런 차원 문제를 해결하는 데 <u>특잇값 분해</u>, <u>주성분 분석</u> 등이 쓰였지만, 차원이 수백만 개일 때는 잘 적용되지 않음.\n",
        "  * 작업에 특화된 데이터에서 학습된(혹은 미세 튜닝된) 표현은 현재 작업에 최적"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwlkJ-jHdp0C",
        "outputId": "4f12024d-d596-494c-c927-411db44482d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.1.tar.gz (647 kB)\n",
            "\u001b[K     |████████████████████████████████| 647 kB 4.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.1-cp37-cp37m-linux_x86_64.whl size=395180 sha256=c5eed8121de21f6887fa9393c8761b8fd933a4f51512b37b925db40b1cccf6cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/94/bf/92cb0e4fef8770fe9c6df0ba588fca30ab7c306b6048ae8a54\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.1\n"
          ]
        }
      ],
      "source": [
        "!pip install annoy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOIfNGvIkRvg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from annoy import AnnoyIndex\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv5iJx4jkb8I"
      },
      "outputs": [],
      "source": [
        "class PreTrainedEmbeddings(object): # 사전 훈련된 단어 벡터 사용을 위한 래퍼 클래스\n",
        "  def __init__(self, word_to_index, word_vectors): # word_to_index(dict): 단어에서 정수로 매핑\n",
        "                                                   # word_vectors (numpy 배열의 리스트)\n",
        "    self.word_to_index = word_to_index\n",
        "    self.word_vectors = word_vectors\n",
        "    self.index_to_word = {v: k for k,v in self.word_to_index.items()}\n",
        "\n",
        "    self.index = AnnoyIndex(len(word_vectors[0]), metric='euclidean')\n",
        "    print('인덱스 생성 중')\n",
        "    for _, i in self.word_to_index.items():\n",
        "      self.index.add_item(i, self.word_vectors[i])\n",
        "    self.index.build(50)\n",
        "    print('완료')\n",
        "\n",
        "  @classmethod\n",
        "  def from_embeddings_file(cls, embedding_file): # 사전 훈련된 벡터 파일에서 객체를 만듦\n",
        "                                                 # embeding_file(str) : 파일 위치\n",
        "                                                 # 반환값 : PretrainedEmbeddings의 인스턴스\n",
        "    word_to_index = {}\n",
        "    word_vectors = []\n",
        "\n",
        "    with open(embedding_file) as fp:\n",
        "      for line in fp.readlines():\n",
        "        line = line.split(\" \")\n",
        "        word = line[0]\n",
        "        vec = np.array([float(x) for x in line[1:]])\n",
        "\n",
        "        word_to_index[word] = len(word_to_index)\n",
        "        word_vectors.append(vec)\n",
        "\n",
        "    return cls(word_to_index, word_vectors)\n",
        "\n",
        "  def get_embedding(self, word): # 반환값: 임베딩(numpy.ndarray)\n",
        "    return self.word_vectors[self.word_to_index[word]]\n",
        "\n",
        "  def get_closet_to_vector(self, vector, n=1): # 벡터가 주어지면 n개의 최근접 이웃 반환\n",
        "                                                # vector (np.ndarray) : Annoy 인덱스에 있는 벡터의 크기와 같아야햠\n",
        "                                                # n (int) : 반환될 이웃의 개수\n",
        "                                                # 반환값: [str,str '''] 주어진 벡터와 가장 가까운 단어, 단 단어는 거리순으로 정렬되어 있지 않음\n",
        "    nn_indices = self.index.get_nns_by_vector(vector, n)\n",
        "    return [self.index_to_word[neighbor] for neighbor in nn_indices]\n",
        "\n",
        "  def compute_and_print_analogy(self, word1, word2, word3): # 단어 임베딩을 사용한 유추 결과 출력\n",
        "                                                            # word1이 word2일 때 word3은 __\n",
        "                                                            # 이 메서드는 word1 : word2 :: word3 : word4를 출력\n",
        "    vec1 = self.get_embedding(word1)\n",
        "    vec2 = self.get_embedding(word2)\n",
        "    vec3 = self.get_embedding(word3)\n",
        "\n",
        "    # 네 번째 임베딩 계산\n",
        "    spatial_relationship = vec2 - vec1\n",
        "    vec4 = vec3 + spatial_relationship\n",
        "\n",
        "    closest_words = self.get_closet_to_vector(vec4, n=4)\n",
        "    existing_words = set([word1, word2, word3])\n",
        "    closest_words = [word for word in closest_words if word not in existing_words]\n",
        "\n",
        "    if len(closest_words)==0:\n",
        "      print('계산된 벡터와 가장 가까운 이웃을 찾을 수 없음')\n",
        "      return\n",
        "    \n",
        "    for word4 in closest_words:\n",
        "      print(\"{} : {} :: {} : {}\".format(word1,word2,word3,word4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IORdytXwohaG",
        "outputId": "75b01543-b9d3-433b-8ec5-17c6fbed15ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-09-16 06:47:13--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-09-16 06:47:13--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-09-16 06:47:13--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 40s  \n",
            "\n",
            "2022-09-16 06:49:54 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "# GloVe 데이터를 다운로드\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!mkdir -p data/glove\n",
        "!mv glove.6B.100d.txt data/glove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgkrO7cSrmpj"
      },
      "source": [
        "단어 임베딩의 핵심기능은 <u>단어 사용에서 규칙적으로 나타는 구문과 의미 관계를 인코딩하는 것</u>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eoty47RmokPe",
        "outputId": "5d41991c-bdbd-450b-d331-9669d6638b28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "인덱스 생성 중\n",
            "완료\n"
          ]
        }
      ],
      "source": [
        "embeddings = PreTrainedEmbeddings.from_embeddings_file('data/glove/glove.6B.100d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ_TZcqBol6W",
        "outputId": "806ab7cb-3544-48f6-caeb-b2e865dd5c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "man : he :: woman : she\n",
            "man : he :: woman : never\n"
          ]
        }
      ],
      "source": [
        "# 성별 명사와 대명사의 관계\n",
        "embeddings.compute_and_print_analogy('man', 'he', 'woman')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySo8Nkyiom12",
        "outputId": "9180d796-c788-40f8-85b4-6b8d4440c693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fly : plane :: sail : ship\n",
            "fly : plane :: sail : vessel\n"
          ]
        }
      ],
      "source": [
        "# 동사-명사 관계\n",
        "embeddings.compute_and_print_analogy('fly', 'plane', 'sail')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSVu2VC3onzG",
        "outputId": "afcbae7d-64a3-4f7b-dadf-844ac62d3c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat : kitten :: dog : puppy\n",
            "cat : kitten :: dog : toddler\n",
            "cat : kitten :: dog : sleds\n"
          ]
        }
      ],
      "source": [
        "# 명사-명사 관계\n",
        "embeddings.compute_and_print_analogy('cat', 'kitten', 'dog')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4a2jZW6opCO",
        "outputId": "645be82c-5c64-43f5-ac29-846df2cb672e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "blue : color :: dog : animal\n",
            "blue : color :: dog : breed\n",
            "blue : color :: dog : pet\n"
          ]
        }
      ],
      "source": [
        "# 상위어 (더 넓은 범주)\n",
        "embeddings.compute_and_print_analogy('blue', 'color', 'dog')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqM8Yc0hoqtm",
        "outputId": "038edb7b-3c12-41c1-dd03-37e074d4f553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fast : fastest :: young : youngest\n",
            "fast : fastest :: young : sixth\n",
            "fast : fastest :: young : fifth\n",
            "fast : fastest :: young : third\n"
          ]
        }
      ],
      "source": [
        "# 비교급\n",
        "embeddings.compute_and_print_analogy('fast', 'fastest', 'young')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfFA1RhJosDG",
        "outputId": "7b3c0a94-36cc-406c-c1b7-32b513210bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toe : foot :: finger : hand\n",
            "toe : foot :: finger : attached\n",
            "toe : foot :: finger : apart\n"
          ]
        }
      ],
      "source": [
        "# 부분에서 전체\n",
        "embeddings.compute_and_print_analogy('toe', 'foot', 'finger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcJ7AH_TotTw",
        "outputId": "9d716152-410e-4908-f3f9-b0885722018c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "talk : communicate :: read : interpret\n",
            "talk : communicate :: read : memorize\n",
            "talk : communicate :: read : instructions\n"
          ]
        }
      ],
      "source": [
        "# 방식 차이\n",
        "embeddings.compute_and_print_analogy('talk', 'communicate', 'read')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aofHz9f3ouUh",
        "outputId": "351c668a-bbcb-49d5-8a52-5a6b266e737f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "blue : democrat :: red : republican\n",
            "blue : democrat :: red : congressman\n",
            "blue : democrat :: red : senator\n"
          ]
        }
      ],
      "source": [
        "# 전체 의미 표현 (관습/인물)\n",
        "embeddings.compute_and_print_analogy('blue', 'democrat', 'red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El9TEhuXovYx",
        "outputId": "ceeb268f-95b5-40f4-838f-e471af50b03a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "man : king :: woman : queen\n",
            "man : king :: woman : throne\n",
            "man : king :: woman : prince\n"
          ]
        }
      ],
      "source": [
        "# 단어 임베딩에 인코딩된 성별과 같은 보호 속성에 주의. 이로 인해 하위 모델에서 원치 않는 편향이 발생할 수 있음\n",
        "embeddings.compute_and_print_analogy('man', 'king', 'woman')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5zs85JmoxUg",
        "outputId": "32aa8f34-0a06-441a-94ab-db637e22852f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "man : doctor :: woman : nurse\n",
            "man : doctor :: woman : physician\n"
          ]
        }
      ],
      "source": [
        "# 벡터에 인코딩된 문화적 성별 편견\n",
        "embeddings.compute_and_print_analogy('man', 'doctor', 'woman')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDrkxDN-oypw",
        "outputId": "a34928c5-20f9-433a-c00b-480c942f547c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fast : fastest :: small : smallest\n",
            "fast : fastest :: small : largest\n",
            "fast : fastest :: small : registered\n",
            "fast : fastest :: small : placing\n"
          ]
        }
      ],
      "source": [
        "# 동시에 등장하는 정보로 의미를 인코딩 하는 위험을 보여주는 예\n",
        "embeddings.compute_and_print_analogy('fast', 'fastest', 'small')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaBoiHFFv07I"
      },
      "source": [
        "# CBOW 임베딩 학습하기\n",
        " * nn.Embedding : 임베딩 행렬을 캡슐화, Embedding 층을 사용하여 토큰의 정수 ID를 신경망 계산에 사용되는 벡터로 매핑  \n",
        " 옵티마이저는 모델 가중치를 업데이트할 때 이 벡터값도 업데이트해서 손실을 최소화함\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es-5pPAboz4w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs3qwLmxwkv4"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object): # 매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스\n",
        "  def __init__(self, token_to_idx = None, mask_token=\"<MASK>\", add_unk=True, unk_token=\"<UNK>\") : # token_to_index (dict) : 기존 토큰-인덱스 매핑 딕셔너리\n",
        "                                                                                                 # mask_token (str) : Vocabulary에 추가할 MASK 토큰. 모델 파라미터를 업데이트하는데 사용하지 않는 위치를 나타냄\n",
        "                                                                                                 # add_unk (bool) : UNK 토큰을 추가할지 지정하는 플래그\n",
        "                                                                                                 # unk_token (str) : Vocabulary에 추가할 UNK 토큰\n",
        "    if token_to_idx is None: \n",
        "      token_to_idx = {}\n",
        "    self._token_to_idx = token_to_idx\n",
        "    self._idx_to_token = {idx:token for token, idx in self._token_to_idx.items()}\n",
        "    self._add_unk = add_unk\n",
        "    self._unk_token = unk_token\n",
        "    self._mask_token = mask_token\n",
        "    self.mask_index = self.add_token(self._mask_token)\n",
        "    self.unk_index = -1\n",
        "    if add_unk:\n",
        "      self.unk_index = self.add_token(unk_token)\n",
        "    \n",
        "  def to_serializable(self): # 직렬화할 수 있는 딕셔너리를 반환\n",
        "    return {'token_to_idx':self._token_to_idx,\n",
        "            'add_unk':self._add_unk,\n",
        "            'unk_token':self._unk_token,\n",
        "            'mask_token':self._mask_token}\n",
        "  @classmethod\n",
        "  def from_serializable(cls,contents): # 직렬화된 딕셔너리에서 Vocabulary 객체를 만듦\n",
        "    return cls(**contents)\n",
        "\n",
        "  def add_token(self, token): # 토큰을 기반으로 매핑 딕셔너리를 업데이트\n",
        "                              # token (str) : Vocabulary에 추가할 토큰\n",
        "                              # 반환값 index(int) : 토큰에 상응하는 정수\n",
        "    if token in self._token_to_idx:\n",
        "      index = self._token_to_idx[token]\n",
        "    else :\n",
        "      index = len(self._token_to_idx)\n",
        "      self._token_to_idx[token] = index\n",
        "      self._idx_to_token[index] = token\n",
        "    return index\n",
        "\n",
        "  def add_many(self, tokens): # 토큰 리스트를 Vocabulary에 추가\n",
        "                              # tokens (list) : 문자열 토큰 리스트\n",
        "                              # 반환값 indices (list) : 토큰 리스트에 상응되는 인덱스 리스트\n",
        "    return [self.add_token(token) for token in tokens]\n",
        "\n",
        "  def lookup_token(self, token): # 토큰에 대응하는 인덱스 추출, 토큰이 없으면 UNK 인덱스 반환. 단 UNK 토큰을 사용하려면(Vocabulary에 추가하기 위해) 'unk_index'가 0보다 커야함\n",
        "                                 # token (str) : 찾을 토큰\n",
        "                                 # 반환값 index (int) : 토큰에 해당하는 인덱스\n",
        "    if self.unk_index >= 0 :\n",
        "      return self._token_to_idx.get(token, self.unk_index)\n",
        "    else :\n",
        "      return self._token_to_idx[token]\n",
        "    \n",
        "  def lookup_index(self, index): # 인덱스에 해당하는 토큰을 반환\n",
        "                                 # index (int) : 찾을 인덱스\n",
        "                                 # 반환값 token (str) : 인덱스에 해당하는 토큰\n",
        "    if index not in self._idx_to_token[index]: # KeyErr : 인덱스가 Vocabulary에 없을 때 발생\n",
        "      raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "    return self._idx_to_token[index]\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self._token_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yqcLZKg5OXP"
      },
      "outputs": [],
      "source": [
        "class CBOWVectorizer(object) : # 어휘 사전을 생성하고 관리\n",
        "  def __init__(self, cbow_vocab): # cbow_vocab (Vocabulary): 단어를 정수에 매핑\n",
        "    self.cbow_vocab = cbow_vocab\n",
        "  \n",
        "  def vectorize(self, context, vector_length = -1): # context (str) : 공백으로 나누어진 단어 문자열\n",
        "                                                    # vector_length (int) : 인덱스 벡터의 길이 매개변수\n",
        "                                                    # 문맥의 토큰 수가 최대 길이보다 적으면 나머지 항목은 0으로 채워짐(패딩)\n",
        "    indices = [self.cbow_vocab.lookup_token(token) for token in context.split(' ')]\n",
        "    if vector_length < 0:\n",
        "      vector_length = len(indices)\n",
        "    \n",
        "    out_vector = np.zeros(vector_length, dtype=np.int64)\n",
        "    out_vector[:len(indices)] = indices\n",
        "    out_vector[len(indices):] = self.cbow_vocab.mask_index\n",
        "\n",
        "    return out_vector\n",
        "  @classmethod\n",
        "  def from_dataframe(cls, cbow_df): # 데이터셋 데이터프레임에서 Vectorizer 객체를 만듦\n",
        "                                    # cbow_df (pandas.DataFrame) : 타깃 데이터셋\n",
        "                                    # 반환값 CBOWVectorizer 객체\n",
        "    cbow_vocab = Vocabulary()\n",
        "    for index, row in cbow_df.iterrows():\n",
        "      for token in row.context.split(' '):\n",
        "        cbow_vocab.add_token(token)\n",
        "      cbow_vocab.add_token(row.target)\n",
        "\n",
        "    return cls(cbow_vocab)\n",
        "\n",
        "  @classmethod\n",
        "  def from_serializable(cls, contents):\n",
        "    cbow_vocab = \\\n",
        "        Vocabulary.from_serializable(contents['cbow_vocab'])\n",
        "    return cls(cbow_vocab=cbow_vocab)\n",
        "\n",
        "  def to_serializable(self):\n",
        "    return {'cbow_vocab' : self.cbow_vocab.to_serializable()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-I3_YoT9uXg"
      },
      "outputs": [],
      "source": [
        "class CBOWDataset(Dataset):\n",
        "  def __init__(self, cbow_df, vectorizer): # cbow_df (pandans.DataFrame) : 데이터셋\n",
        "                                           # vectorizer (CBOWVectorizer) : 데이터셋에서 만든  CBOWVectorizer 객체\n",
        "    self.cbow_df = cbow_df\n",
        "    self._vectorizer = vectorizer\n",
        "\n",
        "    measure_len = lambda context : len(context.split(\" \"))\n",
        "    self._max_seq_length = max(map(measure_len , cbow_df.context))\n",
        "\n",
        "    self.train_df = self.cbow_df[self.cbow_df.split=='train']\n",
        "    self.train_size = len(self.train_df)\n",
        "\n",
        "    self.val_df = self.cbow_df[self.cbow_df.split=='val']\n",
        "    self.validation_size = len(self.val_df)\n",
        "\n",
        "    self.test_df = self.cbow_df[self.cbow_df.split=='test']\n",
        "    self.test_size = len(self.test_df)   \n",
        "\n",
        "    self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                         'val': (self.val_df, self.validation_size),\n",
        "                         'test': (self.test_df,self.test_size)}\n",
        "    self.set_split('train')\n",
        "\n",
        "  @classmethod\n",
        "  def load_dataset_and_make_vectorizer(cls, cbow_csv): # 데이터셋을 로드하고 처음부터 새로운 Vectorizer 만들기\n",
        "                                                       # cbow_csv (str): 데이터셋의 위치\n",
        "                                                       # 반환값: CBOWDataset의 인스턴스\n",
        "      cbow_df = pd.read_csv(cbow_csv)\n",
        "      train_cbow_df = cbow_df[cbow_df.split=='train']\n",
        "      return cls(cbow_df, CBOWVectorizer.from_dataframe(train_cbow_df))\n",
        "\n",
        "  @classmethod\n",
        "  def load_dataset_and_load_vectorizer(cls, cbow_csv, vectorizer_filepath): # 데이터셋을 로드하고 새로운 CBOWVectorizer 객체를 만듦. 캐시된 CBOWVectorizer 객체를 재사용할 때 사용\n",
        "                                                                            # cbow_csv (str): 데이터셋의 위치\n",
        "                                                                            # vectorizer_filepath (str): CBOWVectorizer 객체의 저장 위치\n",
        "                                                                            # 반환값:CBOWVectorizer의 인스턴스\n",
        "      cbow_df = pd.read_csv(cbow_csv)\n",
        "      vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "      return cls(cbow_df, vectorizer)\n",
        "  @staticmethod\n",
        "  def load_vectorizer_only(vectorizer_filepath): # 파일에서 CBOWvectorizer 객체를 로드하는 정적 메서드\n",
        "                                                   # vectorizer_filepath (str) : 직렬화된 CBOWVectorizer 객체의 위치\n",
        "                                                   # 반환값 : CBOWVectorizer의 인스턴스\n",
        "    with open(vectorizer_filepath) as fp:\n",
        "      return CBOWVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "  def save_vectorizer(self, vectorizer_filepath): # CBOWVectorizer 객체를 Json 형태로 디스크에 저장\n",
        "                                                    # vectorizer_filepath (str) : CBOWVectorizer 객체의 저장 위치\n",
        "    with open(vectorizer_filepath, 'w') as fp:\n",
        "      json.dump(self._vectorizer.to_serializable(), fp) \n",
        "    \n",
        "  def get_vectorizer(self) : # 벡터 변환 객체를 반환\n",
        "    return self._vectorizer\n",
        "    \n",
        "  def set_split(self, split='train'): # 데이터프레임에 있는 열을 사용해 분할 세트 선택\n",
        "    self._target_split = split\n",
        "    self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._target_size\n",
        "\n",
        "  def __getitem__(self, index): # 파이토치 데이터셋의 주요 진입 메서드\n",
        "                                # Vectorizer을 사용해 문맥(왼쪽과 오른쪽 윈도)을 벡터로 변환. 타깃(윈도 가운데 단어)은 Vocabulary를 사용해 정수로 변환\n",
        "                                # index (int) : 데이터 포인트의 인덱스\n",
        "                                # 반환값 : 데이터 포인트의 특성(x_data)과 레이블(y_target)로 이루어진 딕셔너리\n",
        "      row = self._target_df.iloc[index]\n",
        "\n",
        "      context_vector = \\\n",
        "          self._vectorizer.vectorize(row.context, self._max_seq_length)\n",
        "      target_index = self._vectorizer.cbow_vocab.lookup_token(row.target)\n",
        "\n",
        "      return {'x_data': context_vector,\n",
        "              'y_target': target_index}\n",
        "\n",
        "  def get_num_batches(self, batch_size): # 배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수 반환                                      \n",
        "      return len(self) // batch_size\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True, # 파이토치 DataLoader를 감싸고 있는 제너레이터 함수\n",
        "                       drop_last=True, device=\"cpu\"):     # 각 텐서를 지정된 장치로 이동\n",
        "  dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "  for data_dict in dataloader:\n",
        "      out_data_dict = {}\n",
        "      for name, tensor in data_dict.items():\n",
        "          out_data_dict[name] = data_dict[name].to(device)\n",
        "      yield out_data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "159L31EOBgR4"
      },
      "outputs": [],
      "source": [
        "class CBOWClassifier(nn.Module): # Embedding 층을 사용해 문맥의 단어를 나타내는 인덱스를 각 단어에 대한 벡터로 만듦\n",
        "                                 # 전반적인 문맥을 감지하도록 벡터를 결합\n",
        "                                 # Linear 층에서 문맥 벡터를 사용해 예측 백터를 계산. 이 예측 벡터는 전체 어휘 사전에 대한 확률 분포 \n",
        "    def __init__(self, vocabulary_size, embedding_size, padding_idx=0): # vocabulary_size (int): 어휘 사전 크기, 임베딩 개수와 예측 벡터 크기를 결정\n",
        "                                                                        # embedding_size (int): 임베딩 크기\n",
        "                                                                        # padding_idx (int): 기본값 0; 임베딩은 이 인덱스를 사용하지 않음. 데이터 포인트 길이가 모두 같지 않을 때 Embedding층에 패딩하는 데 사용.\n",
        "                                                                        #                              해당 인덱스에 상응하는 벡터와 그레이디언트를 모두 0으로 만듦\n",
        "        super(CBOWClassifier, self).__init__()\n",
        "        \n",
        "        self.embedding =  nn.Embedding(num_embeddings=vocabulary_size, \n",
        "                                       embedding_dim=embedding_size,\n",
        "                                       padding_idx=padding_idx)\n",
        "        self.fc1 = nn.Linear(in_features=embedding_size,\n",
        "                             out_features=vocabulary_size)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False): # 분류기의 정방향 계산\n",
        "                                                  # x_in (torch.Tensor): 입력 데이터 텐서. x_in.shape는 (batch, input_dim)\n",
        "                                                  # apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그. 크로스-엔트로피 손실을 사용하려면 False로 지정\n",
        "                                                  # 반환값 결과 텐서. tensor.shape은 (batch, output_dim)\n",
        "        x_embedded_sum = F.dropout(self.embedding(x_in).sum(dim=1), 0.3)\n",
        "        y_out = self.fc1(x_embedded_sum)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            y_out = F.softmax(y_out, dim=1)\n",
        "            \n",
        "        return y_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct-NnhcpB_Z8"
      },
      "outputs": [],
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state): # 훈련 상태 업데이트\n",
        "                                                  # args: 메인 매개변수\n",
        "                                                  # model: 훈련할 모델\n",
        "                                                  # train_state: 훈련 상태를 담은 딕셔너리\n",
        "                                                  # 반환값 : 새로운 훈련 상태\n",
        "\n",
        "    # 적어도 한 번 모델을 저장\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # 성능이 향상되면 모델을 저장\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # 손실이 나빠지면\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # 조기 종료 단계 업데이트\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # 손실이 감소하면\n",
        "        else:\n",
        "            # 최상의 모델 저장\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # 조기 종료 단계 재설정\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # 조기 종료 여부 확인\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb9Vvh2sCNGO"
      },
      "outputs": [],
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md_3RdWJCOVH",
        "outputId": "34b4d3f1-72a6-4f5c-9453-e89a17ccc7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일 경로: \n",
            "\tmodel_storage/ch5/cbow/vectorizer.json\n",
            "\tmodel_storage/ch5/cbow/model.pth\n",
            "CUDA 사용여부: False\n"
          ]
        }
      ],
      "source": [
        "args = Namespace(\n",
        "    # 날짜와 경로 정보\n",
        "    cbow_csv=\"data/books/frankenstein_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch5/cbow\",\n",
        "    # 모델 하이퍼파라미터\n",
        "    embedding_size=50,\n",
        "    # 훈련 하이퍼파라미터\n",
        "    seed=1337,\n",
        "    num_epochs=100,\n",
        "    learning_rate=0.0001,\n",
        "    batch_size=32,\n",
        "    early_stopping_criteria=5,\n",
        "    # 실행 옵션\n",
        "    cuda=True,\n",
        "    catch_keyboard_interrupt=True,\n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"파일 경로: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "\n",
        "# CUDA 체크\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"CUDA 사용여부: {}\".format(args.cuda))\n",
        "\n",
        "# 재현성을 위해 시드 설정\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# 디렉토리 처리\n",
        "handle_dirs(args.save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1vLFFkfCQDI",
        "outputId": "5002c4a5-b9af-4740-a283-aed75df38490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2022-09-16 08:19:55--  https://git.io/JtX5A\n",
            "Resolving git.io (git.io)... 140.82.112.21\n",
            "Connecting to git.io (git.io)|140.82.112.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_2_CBOW/data/download.py [following]\n",
            "--2022-09-16 08:19:55--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_2_CBOW/data/download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1572 (1.5K) [text/plain]\n",
            "Saving to: ‘data/download.py’\n",
            "\n",
            "data/download.py    100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-16 08:19:55 (20.9 MB/s) - ‘data/download.py’ saved [1572/1572]\n",
            "\n",
            "--2022-09-16 08:19:55--  https://git.io/JtX5F\n",
            "Resolving git.io (git.io)... 140.82.112.21\n",
            "Connecting to git.io (git.io)|140.82.112.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_2_CBOW/data/get-all-data.sh [following]\n",
            "--2022-09-16 08:19:55--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_5/5_2_CBOW/data/get-all-data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 508 [text/plain]\n",
            "Saving to: ‘data/get-all-data.sh’\n",
            "\n",
            "data/get-all-data.s 100%[===================>]     508  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-16 08:19:55 (17.2 MB/s) - ‘data/get-all-data.sh’ saved [508/508]\n",
            "\n",
            "/content/data\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget https://git.io/JtX5A -O data/download.py\n",
        "!wget https://git.io/JtX5F -O data/get-all-data.sh\n",
        "!chmod 755 data/get-all-data.sh\n",
        "%cd data\n",
        "!./get-all-data.sh\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzMw5mBeCR8A",
        "outputId": "3a3f8f04-b7c5-49b0-b7b0-00c0bc05dcb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터셋을 로드하고 Vectorizer를 만듭니다\n"
          ]
        }
      ],
      "source": [
        "if args.reload_from_files:\n",
        "    print(\"데이터셋과 Vectorizer를 로드합니다\")\n",
        "    dataset = CBOWDataset.load_dataset_and_load_vectorizer(args.cbow_csv,\n",
        "                                                           args.vectorizer_file)\n",
        "else:\n",
        "    print(\"데이터셋을 로드하고 Vectorizer를 만듭니다\")\n",
        "    dataset = CBOWDataset.load_dataset_and_make_vectorizer(args.cbow_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = CBOWClassifier(vocabulary_size=len(vectorizer.cbow_vocab), \n",
        "                            embedding_size=args.embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "cfaf842cc40242ab8bf283a70e862b0a",
            "ecad3d1b6d334bf0b75caac97fd73486",
            "e3d9c1a0a8c441ea9dc504f2e11b5a2f",
            "8728590a8f22427dbd1f037a174f7556",
            "974d79f1685e45129d5da7f118a55977",
            "17ddad575524460abeb80005deb72ee5",
            "7aee607a66454c329c3518315fb380ab",
            "d5a0173a85384264a420723cf0040ac4",
            "b6e0a863916848e2b29b4dbb98fc8913",
            "c022f2ce3f0e4535a1297ef72e9a3c2d",
            "6cc6553a9432420db196d5faff442dc9",
            "97850586b06c4a8d8cf650c70e3fd165",
            "21fe45c25ec94aa19655b9e6cfcc68aa",
            "23cce7747f7d4e219b771060c871f3ca",
            "dc39f245b4b14a8fb2d77f9f491e54df",
            "2bf76b7e6ad14868be7744931baf12e6",
            "ba392951061a4a7da7b0aca6f825b062",
            "8c57ba554ff54d2f8cc0a2754f38591b",
            "950093fe5f954c75af19de21f2ce0913",
            "07d61e13da63454a9b3a21a125c99f4a",
            "95f0a61cd5e14b3ab2c93d941106d84a",
            "493b7c0c97214ad2ae91fc43828c2833",
            "bf384e161e6a4b5db7a0f60841ec5cdc",
            "256fcf50f0ad48218d0e1328704adbb0",
            "6591a781d87b4338868d85bef13762a5",
            "cbea6346c137422bbab9b60338bcca10",
            "6dcdd5e8e3e841f28f8b11c38cd56aa5",
            "2231e0c3cebc451d9e36aa29da14cdde",
            "67b3add488a54cd8bfeae4b32c616518",
            "a044be4713b14af8935119939f1118f0",
            "d2159f15ccb74367814948d54245e270",
            "0fe79ef0b1bb4d07b4238cfc63a3323a",
            "4057d2a22ed8477781f79d75f06ea1d4"
          ]
        },
        "id": "dk16Qmt9CUrx",
        "outputId": "1b89a320-0a73-4523-c61f-c808bcbfeca7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfaf842cc40242ab8bf283a70e862b0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97850586b06c4a8d8cf650c70e3fd165",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "split=train:   0%|          | 0/1984 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf384e161e6a4b5db7a0f60841ec5cdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "split=val:   0%|          | 0/425 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classifier = classifier.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min', factor=0.5,\n",
        "                                                 patience=1)\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
        "                               total=args.num_epochs,\n",
        "                               position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
        "                               total=dataset.get_num_batches(args.batch_size), \n",
        "                               position=1, \n",
        "                               leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
        "                             total=dataset.get_num_batches(args.batch_size), \n",
        "                             position=1, \n",
        "                             leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # 훈련 세트에 대한 순회\n",
        "\n",
        "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 훈련 과정은 5단계로 이루어집니다\n",
        "\n",
        "            # --------------------------------------\n",
        "            # 단계 1. 그레이디언트를 0으로 초기화합니다\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 단계 2. 출력을 계산합니다\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # 단계 3. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 4. 손실을 사용해 그레이디언트를 계산합니다\n",
        "            loss.backward()\n",
        "\n",
        "            # 단계 5. 옵티마이저로 가중치를 업데이트합니다\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            \n",
        "            # 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 바 업데이트\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # 검증 세트에 대한 순회\n",
        "\n",
        "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # 단계 1. 출력을 계산합니다\n",
        "            y_pred =  classifier(x_in=batch_dict['x_data'])\n",
        "\n",
        "            # 단계 2. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 3. 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s53hFbKoC_hJ"
      },
      "outputs": [],
      "source": [
        "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "classifier = classifier.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # 출력 계산\n",
        "    y_pred =  classifier(x_in=batch_dict['x_data'])\n",
        "    \n",
        "    # 손실 계산\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # 정확도 계산\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S7E1ulY1DBVO",
        "outputId": "13c75564-2a3d-4b83-b0c7-221286075210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 손실: 7.672896379583021;\n",
            "테스트 정확도: 13.007352941176478\n"
          ]
        }
      ],
      "source": [
        "print(\"테스트 손실: {};\".format(train_state['test_loss']))\n",
        "print(\"테스트 정확도: {}\".format(train_state['test_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y1pHq6FLDCjI"
      },
      "outputs": [],
      "source": [
        "def pretty_print(results):\n",
        "    \"\"\"\n",
        "    임베딩 결과를 출력\n",
        "    \"\"\"\n",
        "    for item in results:\n",
        "        print (\"...[%.2f] - %s\"%(item[1], item[0]))\n",
        "\n",
        "def get_closest(target_word, word_to_idx, embeddings, n=5):\n",
        "    \"\"\"\n",
        "    n개의 최근접 단어를 찾습니다.\n",
        "    \"\"\"\n",
        "\n",
        "    # 다른 모든 단어까지 거리를 계산\n",
        "    word_embedding = embeddings[word_to_idx[target_word.lower()]]\n",
        "    distances = []\n",
        "    for word, index in word_to_idx.items():\n",
        "        if word == \"<MASK>\" or word == target_word:\n",
        "            continue\n",
        "        distances.append((word, torch.dist(word_embedding, embeddings[index])))\n",
        "    \n",
        "    results = sorted(distances, key=lambda x: x[1])[1:n+2]\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c4SA97MDD-w"
      },
      "outputs": [],
      "source": [
        "word = input('단어를 입력해 주세요: ')\n",
        "embeddings = classifier.embedding.weight.data\n",
        "word_to_idx = vectorizer.cbow_vocab._token_to_idx\n",
        "pretty_print(get_closest(word, word_to_idx, embeddings, n=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUkS6CXHDFQR"
      },
      "outputs": [],
      "source": [
        "target_words = ['frankenstein', 'monster', 'science', 'sickness', 'lonely', 'happy']\n",
        "\n",
        "embeddings = classifier.embedding.weight.data\n",
        "word_to_idx = vectorizer.cbow_vocab._token_to_idx\n",
        "\n",
        "for target_word in target_words: \n",
        "    print(f\"======={target_word}=======\")\n",
        "    if target_word not in word_to_idx:\n",
        "        print(\"Not in vocabulary\")\n",
        "        continue\n",
        "    pretty_print(get_closest(target_word, word_to_idx, embeddings, n=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBXgXoRwDiEN"
      },
      "source": [
        "전이 학습 : 머신러닝에서 한 작업에서 훈련된 모델을 다른 작업의 초기 모델로 사용하는 방식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyu_Vm4PZX7z"
      },
      "source": [
        "AG 뉴스 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opGq5XykypB3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryApF_G1jsQ4"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다 \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다 \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\" 토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
        "\n",
        "        매개변수:\n",
        "            token (str): Vocabulary에 추가할 토큰\n",
        "        반환값:\n",
        "            index (int): 토큰에 상응하는 정수\n",
        "        \"\"\"\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "            \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            tokens (list): 문자열 토큰 리스트\n",
        "        반환값:\n",
        "            indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"토큰에 대응하는 인덱스를 추출합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            token (str): 찾을 토큰 \n",
        "        반환값:\n",
        "            index (int): 토큰에 해당하는 인덱스\n",
        "        \"\"\"\n",
        "        return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다.\n",
        "        \n",
        "        매개변수: \n",
        "            index (int): 찾을 인덱스\n",
        "        반환값:\n",
        "            token (str): 인텍스에 해당하는 토큰\n",
        "        에러:\n",
        "            KeyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNazWmzHjuQo"
      },
      "outputs": [],
      "source": [
        "class SequenceVocabulary(Vocabulary):\n",
        "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
        "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
        "                 end_seq_token=\"<END>\"):\n",
        "\n",
        "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
        "\n",
        "        self._mask_token = mask_token\n",
        "        self._unk_token = unk_token\n",
        "        self._begin_seq_token = begin_seq_token\n",
        "        self._end_seq_token = end_seq_token\n",
        "\n",
        "        self.mask_index = self.add_token(self._mask_token)\n",
        "        self.unk_index = self.add_token(self._unk_token)\n",
        "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
        "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        contents = super(SequenceVocabulary, self).to_serializable()\n",
        "        contents.update({'unk_token': self._unk_token,\n",
        "                         'mask_token': self._mask_token,\n",
        "                         'begin_seq_token': self._begin_seq_token,\n",
        "                         'end_seq_token': self._end_seq_token})\n",
        "        return contents\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\" 토큰에 대응하는 인덱스를 추출합니다.\n",
        "        토큰이 없으면 UNK 인덱스를 반환합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            token (str): 찾을 토큰 \n",
        "        반환값:\n",
        "            index (int): 토큰에 해당하는 인덱스\n",
        "        노트:\n",
        "            UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
        "            `unk_index`가 0보다 커야 합니다.\n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9mSaxnwjvaz"
      },
      "outputs": [],
      "source": [
        "class NewsVectorizer(object):\n",
        "    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n",
        "    def __init__(self, title_vocab, category_vocab):\n",
        "        self.title_vocab = title_vocab\n",
        "        self.category_vocab = category_vocab\n",
        "\n",
        "    def vectorize(self, title, vector_length=-1):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            title (str): 공백으로 나누어진 단어 문자열\n",
        "            vector_length (int): 인덱스 벡터의 길이 매개변수\n",
        "        반환값:\n",
        "            벡터로 변환된 제목 (numpy.array)\n",
        "        \"\"\"\n",
        "        indices = [self.title_vocab.begin_seq_index]\n",
        "        indices.extend(self.title_vocab.lookup_token(token) \n",
        "                       for token in title.split(\" \"))\n",
        "        indices.append(self.title_vocab.end_seq_index)\n",
        "\n",
        "        if vector_length < 0:\n",
        "            vector_length = len(indices)\n",
        "\n",
        "        out_vector = np.zeros(vector_length, dtype=np.int64)\n",
        "        out_vector[:len(indices)] = indices\n",
        "        out_vector[len(indices):] = self.title_vocab.mask_index\n",
        "\n",
        "        return out_vector\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, news_df, cutoff=25):\n",
        "        \"\"\"데이터셋 데이터프레임에서 Vectorizer 객체를 만듭니다\n",
        "        \n",
        "        매개변수:\n",
        "            news_df (pandas.DataFrame): 타깃 데이터셋\n",
        "            cutoff (int): Vocabulary에 포함할 빈도 임곗값\n",
        "        반환값:\n",
        "            NewsVectorizer 객체\n",
        "        \"\"\"\n",
        "        category_vocab = Vocabulary()        \n",
        "        for category in sorted(set(news_df.category)):\n",
        "            category_vocab.add_token(category)\n",
        "\n",
        "        word_counts = Counter()\n",
        "        for title in news_df.title:\n",
        "            for token in title.split(\" \"):\n",
        "                if token not in string.punctuation:\n",
        "                    word_counts[token] += 1\n",
        "        \n",
        "        title_vocab = SequenceVocabulary()\n",
        "        for word, word_count in word_counts.items():\n",
        "            if word_count >= cutoff:\n",
        "                title_vocab.add_token(word)\n",
        "        \n",
        "        return cls(title_vocab, category_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        title_vocab = \\\n",
        "            SequenceVocabulary.from_serializable(contents['title_vocab'])\n",
        "        category_vocab =  \\\n",
        "            Vocabulary.from_serializable(contents['category_vocab'])\n",
        "\n",
        "        return cls(title_vocab=title_vocab, category_vocab=category_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'title_vocab': self.title_vocab.to_serializable(),\n",
        "                'category_vocab': self.category_vocab.to_serializable()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDAhXhfljwrR"
      },
      "outputs": [],
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, news_df, vectorizer):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            news_df (pandas.DataFrame): 데이터셋\n",
        "            vectorizer (NewsVectorizer): 데이터셋에서 만든 NewsVectorizer 객체\n",
        "        \"\"\"\n",
        "        self.news_df = news_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        # +1 if only using begin_seq, +2 if using both begin and end seq tokens\n",
        "        measure_len = lambda context: len(context.split(\" \"))\n",
        "        self._max_seq_length = max(map(measure_len, news_df.title)) + 2\n",
        "        \n",
        "\n",
        "        self.train_df = self.news_df[self.news_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.news_df[self.news_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.news_df[self.news_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "        # 클래스 가중치\n",
        "        class_counts = news_df.category.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self._vectorizer.category_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "        \n",
        "        \n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, news_csv):\n",
        "        \"\"\"데이터셋을 로드하고 처음부터 새로운 Vectorizer 만들기\n",
        "        \n",
        "        매개변수:\n",
        "            news_csv (str): 데이터셋의 위치\n",
        "        반환값:\n",
        "            NewsDataset의 인스턴스\n",
        "        \"\"\"\n",
        "        news_df = pd.read_csv(news_csv)\n",
        "        train_news_df = news_df[news_df.split=='train']\n",
        "        return cls(news_df, NewsVectorizer.from_dataframe(train_news_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, news_csv, vectorizer_filepath):\n",
        "        \"\"\" 데이터셋과 새로운 Vectorizer 객체를 로드합니다.\n",
        "        캐시된 Vectorizer 객체를 재사용할 때 사용합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            news_csv (str): 데이터셋의 위치\n",
        "            vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
        "        반환값:\n",
        "            NewsDataset의 인스턴스\n",
        "        \"\"\"\n",
        "        news_df = pd.read_csv(news_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(news_csv, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"파일에서 Vectorizer 객체를 로드하는 정적 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): 직렬화된 Vectorizer 객체의 위치\n",
        "        반환값:\n",
        "            NewsVectorizer의 인스턴스\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return NameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\"NewsVectorizer 객체를 json 형태로 디스크에 저장합니다\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): NewsVectorizer 객체의 저장 위치\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" 벡터 변환 객체를 반환합니다 \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" 데이터프레임에 있는 열을 사용해 분할 세트를 선택합니다 \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"파이토치 데이터셋의 주요 진입 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            index (int): 데이터 포인트의 인덱스\n",
        "        반환값:\n",
        "            데이터 포인트의 특성(x_data)과 레이블(y_target)로 이루어진 딕셔너리\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        title_vector = \\\n",
        "            self._vectorizer.vectorize(row.title, self._max_seq_length)\n",
        "\n",
        "        category_index = \\\n",
        "            self._vectorizer.category_vocab.lookup_token(row.category)\n",
        "\n",
        "        return {'x_data': title_vector,\n",
        "                'y_target': category_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다\n",
        "        \n",
        "        매개변수:\n",
        "            batch_size (int)\n",
        "        반환값:\n",
        "            배치 개수\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "\n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    파이토치 DataLoader를 감싸고 있는 제너레이터 함수.\n",
        "    걱 텐서를 지정된 장치로 이동합니다.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2sSLTfSjyWb"
      },
      "outputs": [],
      "source": [
        "class NewsClassifier(nn.Module):\n",
        "    def __init__(self, embedding_size, num_embeddings, num_channels, \n",
        "                 hidden_dim, num_classes, dropout_p, \n",
        "                 pretrained_embeddings=None, padding_idx=0):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            embedding_size (int): 임베딩 벡터의 크기\n",
        "            num_embeddings (int): 임베딩 벡터의 개수\n",
        "            num_channels (int): 합성곱 커널 개수\n",
        "            hidden_dim (int): 은닉 차원 크기\n",
        "            num_classes (int): 클래스 개수\n",
        "            dropout_p (float): 드롭아웃 확률\n",
        "            pretrained_embeddings (numpy.array): 사전에 훈련된 단어 임베딩\n",
        "                기본값은 None \n",
        "            padding_idx (int): 패딩 인덱스\n",
        "        \"\"\"\n",
        "        super(NewsClassifier, self).__init__()\n",
        "\n",
        "        if pretrained_embeddings is None:\n",
        "\n",
        "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
        "                                    num_embeddings=num_embeddings,\n",
        "                                    padding_idx=padding_idx)        \n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
        "                                    num_embeddings=num_embeddings,\n",
        "                                    padding_idx=padding_idx,\n",
        "                                    _weight=pretrained_embeddings)\n",
        "        \n",
        "            \n",
        "        self.convnet = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_size, \n",
        "                   out_channels=num_channels, kernel_size=3),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                   kernel_size=3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                   kernel_size=3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                   kernel_size=3),\n",
        "            nn.ELU()\n",
        "        )\n",
        "\n",
        "        self._dropout_p = dropout_p\n",
        "        self.fc1 = nn.Linear(num_channels, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"분류기의 정방향 계산\n",
        "        \n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서 \n",
        "                x_in.shape는 (batch, dataset._max_seq_length)입니다.\n",
        "            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n",
        "                크로스-엔트로피 손실을 사용하려면 False로 지정합니다\n",
        "        반환값:\n",
        "            결과 텐서. tensor.shape은 (batch, num_classes)입니다.\n",
        "        \"\"\"\n",
        "        \n",
        "        # 임베딩을 적용하고 특성과 채널 차원을 바꿉니다\n",
        "        x_embedded = self.emb(x_in).permute(0, 2, 1)\n",
        "\n",
        "        features = self.convnet(x_embedded)\n",
        "\n",
        "        # 평균 값을 계산하여 부가적인 차원을 제거합니다\n",
        "        remaining_size = features.size(dim=2)\n",
        "        features = F.avg_pool1d(features, remaining_size).squeeze(dim=2)\n",
        "        features = F.dropout(features, p=self._dropout_p)\n",
        "        \n",
        "        # MLP 분류기\n",
        "        intermediate_vector = F.relu(F.dropout(self.fc1(features), p=self._dropout_p))\n",
        "        prediction_vector = self.fc2(intermediate_vector)\n",
        "\n",
        "        if apply_softmax:\n",
        "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
        "\n",
        "        return prediction_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeKkdPcojzcV"
      },
      "outputs": [],
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\"훈련 상태를 업데이트합니다.\n",
        "\n",
        "    Components:\n",
        "     - 조기 종료: 과대 적합 방지\n",
        "     - 모델 체크포인트: 더 나은 모델을 저장합니다\n",
        "\n",
        "    :param args: 메인 매개변수\n",
        "    :param model: 훈련할 모델\n",
        "    :param train_state: 훈련 상태를 담은 딕셔너리\n",
        "    :returns:\n",
        "        새로운 훈련 상태\n",
        "    \"\"\"\n",
        "\n",
        "    # 적어도 한 번 모델을 저장합니다\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # 성능이 향상되면 모델을 저장합니다\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # 손실이 나빠지면\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # 조기 종료 단계 업데이트\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # 손실이 감소하면\n",
        "        else:\n",
        "            # 최상의 모델 저장\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # 조기 종료 단계 재설정\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # 조기 종료 여부 확인\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asu109SCj0d8"
      },
      "outputs": [],
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "        \n",
        "def load_glove_from_file(glove_filepath):\n",
        "    \"\"\"GloVe 임베딩 로드 \n",
        "    \n",
        "    매개변수:\n",
        "        glove_filepath (str): 임베딩 파일 경로 \n",
        "    반환값:\n",
        "        word_to_index (dict), embeddings (numpy.ndarary)\n",
        "    \"\"\"\n",
        "\n",
        "    word_to_index = {}\n",
        "    embeddings = []\n",
        "    with open(glove_filepath, \"r\") as fp:\n",
        "        for index, line in enumerate(fp):\n",
        "            line = line.split(\" \") # each line: word num1 num2 ...\n",
        "            word_to_index[line[0]] = index # word = line[0] \n",
        "            embedding_i = np.array([float(val) for val in line[1:]])\n",
        "            embeddings.append(embedding_i)\n",
        "    return word_to_index, np.stack(embeddings)\n",
        "\n",
        "def make_embedding_matrix(glove_filepath, words):\n",
        "    \"\"\"\n",
        "    특정 단어 집합에 대한 임베딩 행렬을 만듭니다.\n",
        "    \n",
        "    매개변수:\n",
        "        glove_filepath (str): 임베딩 파일 경로\n",
        "        words (list): 단어 리스트\n",
        "    \"\"\"\n",
        "    word_to_idx, glove_embeddings = load_glove_from_file(glove_filepath)\n",
        "    embedding_size = glove_embeddings.shape[1]\n",
        "    \n",
        "    final_embeddings = np.zeros((len(words), embedding_size))\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word in word_to_idx:\n",
        "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
        "        else:\n",
        "            embedding_i = torch.ones(1, embedding_size)\n",
        "            torch.nn.init.xavier_uniform_(embedding_i)\n",
        "            final_embeddings[i, :] = embedding_i\n",
        "\n",
        "    return final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSjuGedJj1qX"
      },
      "outputs": [],
      "source": [
        "args = Namespace(\n",
        "    # 날짜와 경로 정보\n",
        "    news_csv=\"data/ag_news/news_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch5/document_classification\",\n",
        "    # 모델 하이퍼파라미터\n",
        "    glove_filepath='data/glove/glove.6B.100d.txt', \n",
        "    use_glove=False,\n",
        "    embedding_size=100, \n",
        "    hidden_dim=100, \n",
        "    num_channels=100, \n",
        "    # 훈련 하이퍼파라미터\n",
        "    seed=1337, \n",
        "    learning_rate=0.001, \n",
        "    dropout_p=0.1, \n",
        "    batch_size=128, \n",
        "    num_epochs=100, \n",
        "    early_stopping_criteria=5, \n",
        "    # 실행 옵션\n",
        "    cuda=True, \n",
        "    catch_keyboard_interrupt=True, \n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True\n",
        ") \n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"파일 경로: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "# CUDA 체크\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "    \n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"CUDA 사용여부: {}\".format(args.cuda))\n",
        "\n",
        "# 재현성을 위해 시드 설정\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# 디렉토리 처리\n",
        "handle_dirs(args.save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlLlclXdj-H7"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!wget https://git.io/Jt1NH -O data/download.py\n",
        "!wget https://git.io/Jt1NS -O data/get-all-data.sh\n",
        "!chmod 755 data/get-all-data.sh\n",
        "%cd data\n",
        "!./get-all-data.sh\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6yUCPP_j_FL"
      },
      "outputs": [],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!mkdir -p data/glove\n",
        "!mv glove.6B.100d.txt data/glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67ZTaG4tkAYs"
      },
      "outputs": [],
      "source": [
        "args.use_glove = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOfszbDLkBqL"
      },
      "outputs": [],
      "source": [
        "if args.reload_from_files:\n",
        "    # 체크포인트를 로드합니다.\n",
        "    dataset = NewsDataset.load_dataset_and_load_vectorizer(args.news_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # 데이터셋과 Vectorizer를 만듭니다.\n",
        "    dataset = NewsDataset.load_dataset_and_make_vectorizer(args.news_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "# GloVe를 사용하거나 랜덤하게 임베딩을 초기화합니다\n",
        "if args.use_glove:\n",
        "    words = vectorizer.title_vocab._token_to_idx.keys()\n",
        "    embeddings = make_embedding_matrix(glove_filepath=args.glove_filepath, \n",
        "                                       words=words)\n",
        "    print(\"사전 훈련된 임베딩을 사용합니다\")\n",
        "else:\n",
        "    print(\"사전 훈련된 임베딩을 사용하지 않습니다\")\n",
        "    embeddings = None\n",
        "\n",
        "classifier = NewsClassifier(embedding_size=args.embedding_size, \n",
        "                            num_embeddings=len(vectorizer.title_vocab),\n",
        "                            num_channels=args.num_channels,\n",
        "                            hidden_dim=args.hidden_dim, \n",
        "                            num_classes=len(vectorizer.category_vocab), \n",
        "                            dropout_p=args.dropout_p,\n",
        "                            pretrained_embeddings=embeddings,\n",
        "                            padding_idx=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvLAcRWRkCfZ"
      },
      "outputs": [],
      "source": [
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm_notebook(desc='training routine', \n",
        "                          total=args.num_epochs,\n",
        "                          position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm_notebook(desc='split=train',\n",
        "                          total=dataset.get_num_batches(args.batch_size), \n",
        "                          position=1, \n",
        "                          leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm_notebook(desc='split=val',\n",
        "                        total=dataset.get_num_batches(args.batch_size), \n",
        "                        position=1, \n",
        "                        leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # 훈련 세트에 대한 순회\n",
        "\n",
        "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 훈련 과정은 5단계로 이루어집니다\n",
        "\n",
        "            # --------------------------------------\n",
        "            # 단계 1. 그레이디언트를 0으로 초기화합니다\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 단계 2. 출력을 계산합니다\n",
        "            y_pred = classifier(batch_dict['x_data'])\n",
        "\n",
        "            # 단계 3. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 4. 손실을 사용해 그레이디언트를 계산합니다\n",
        "            loss.backward()\n",
        "\n",
        "            # 단계 5. 옵티마이저로 가중치를 업데이트합니다\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            \n",
        "            # 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 상태 막대 업데이트\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                                  epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # 검증 세트에 대한 순회\n",
        "\n",
        "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # 단계 1. 출력을 계산합니다\n",
        "            y_pred =  classifier(batch_dict['x_data'])\n",
        "\n",
        "            # 단계 2. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 3. 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ICI-_mUkEJA"
      },
      "outputs": [],
      "source": [
        "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산합니다\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # 출력을 계산합니다\n",
        "    y_pred =  classifier(batch_dict['x_data'])\n",
        "    \n",
        "    # 손실을 계산합니다\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # 정확도를 계산합니다\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXB52IYSkFiC"
      },
      "outputs": [],
      "source": [
        "print(\"테스트 손실: {};\".format(train_state['test_loss']))\n",
        "print(\"테스트 정확도: {}\".format(train_state['test_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJFSOyopkGsc"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBpHgHnSkHvY"
      },
      "outputs": [],
      "source": [
        "def predict_category(title, classifier, vectorizer, max_length):\n",
        "    \"\"\"뉴스 제목을 기반으로 카테고리를 예측합니다\n",
        "    \n",
        "    매개변수:\n",
        "        title (str): 원시 제목 문자열\n",
        "        classifier (NewsClassifier): 훈련된 분류기 객체\n",
        "        vectorizer (NewsVectorizer): 해당 Vectorizer\n",
        "        max_length (int): 최대 시퀀스 길이\n",
        "            노트: CNN은 입력 텐서 크기에 민감합니다. \n",
        "                 훈련 데이터처럼 동일한 크기를 갖도록 만듭니다.\n",
        "    \"\"\"\n",
        "    title = preprocess_text(title)\n",
        "    vectorized_title = \\\n",
        "        torch.tensor(vectorizer.vectorize(title, vector_length=max_length))\n",
        "    result = classifier(vectorized_title.unsqueeze(0), apply_softmax=True)\n",
        "    probability_values, indices = result.max(dim=1)\n",
        "    predicted_category = vectorizer.category_vocab.lookup_index(indices.item())\n",
        "\n",
        "    return {'category': predicted_category, \n",
        "            'probability': probability_values.item()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM_T3aUUkIko"
      },
      "outputs": [],
      "source": [
        "def get_samples():\n",
        "    samples = {}\n",
        "    for cat in dataset.val_df.category.unique():\n",
        "        samples[cat] = dataset.val_df.title[dataset.val_df.category==cat].tolist()[:5]\n",
        "    return samples\n",
        "\n",
        "val_samples = get_samples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpeUkj3ZkJVn"
      },
      "outputs": [],
      "source": [
        "classifier = classifier.to(\"cpu\")\n",
        "\n",
        "for truth, sample_group in val_samples.items():\n",
        "    print(f\"True Category: {truth}\")\n",
        "    print(\"=\"*30)\n",
        "    for sample in sample_group:\n",
        "        prediction = predict_category(sample, classifier, \n",
        "                                      vectorizer, dataset._max_seq_length + 1)\n",
        "        print(\"예측: {} (p={:0.2f})\".format(prediction['category'],\n",
        "                                                  prediction['probability']))\n",
        "        print(\"\\t + 샘플: {}\".format(sample))\n",
        "    print(\"-\"*30 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyPiDcZkga5oNZi0KRp+8XLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07d61e13da63454a9b3a21a125c99f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fe79ef0b1bb4d07b4238cfc63a3323a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ddad575524460abeb80005deb72ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21fe45c25ec94aa19655b9e6cfcc68aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba392951061a4a7da7b0aca6f825b062",
            "placeholder": "​",
            "style": "IPY_MODEL_8c57ba554ff54d2f8cc0a2754f38591b",
            "value": "split=train:  96%"
          }
        },
        "2231e0c3cebc451d9e36aa29da14cdde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23cce7747f7d4e219b771060c871f3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950093fe5f954c75af19de21f2ce0913",
            "max": 1984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07d61e13da63454a9b3a21a125c99f4a",
            "value": 1896
          }
        },
        "256fcf50f0ad48218d0e1328704adbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2231e0c3cebc451d9e36aa29da14cdde",
            "placeholder": "​",
            "style": "IPY_MODEL_67b3add488a54cd8bfeae4b32c616518",
            "value": "split=val: 100%"
          }
        },
        "2bf76b7e6ad14868be7744931baf12e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4057d2a22ed8477781f79d75f06ea1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "493b7c0c97214ad2ae91fc43828c2833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6591a781d87b4338868d85bef13762a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a044be4713b14af8935119939f1118f0",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2159f15ccb74367814948d54245e270",
            "value": 424
          }
        },
        "67b3add488a54cd8bfeae4b32c616518": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cc6553a9432420db196d5faff442dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dcdd5e8e3e841f28f8b11c38cd56aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aee607a66454c329c3518315fb380ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8728590a8f22427dbd1f037a174f7556": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c022f2ce3f0e4535a1297ef72e9a3c2d",
            "placeholder": "​",
            "style": "IPY_MODEL_6cc6553a9432420db196d5faff442dc9",
            "value": " 55/100 [52:21&lt;43:03, 57.41s/it]"
          }
        },
        "8c57ba554ff54d2f8cc0a2754f38591b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "950093fe5f954c75af19de21f2ce0913": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f0a61cd5e14b3ab2c93d941106d84a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "974d79f1685e45129d5da7f118a55977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97850586b06c4a8d8cf650c70e3fd165": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21fe45c25ec94aa19655b9e6cfcc68aa",
              "IPY_MODEL_23cce7747f7d4e219b771060c871f3ca",
              "IPY_MODEL_dc39f245b4b14a8fb2d77f9f491e54df"
            ],
            "layout": "IPY_MODEL_2bf76b7e6ad14868be7744931baf12e6"
          }
        },
        "a044be4713b14af8935119939f1118f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e0a863916848e2b29b4dbb98fc8913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba392951061a4a7da7b0aca6f825b062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf384e161e6a4b5db7a0f60841ec5cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_256fcf50f0ad48218d0e1328704adbb0",
              "IPY_MODEL_6591a781d87b4338868d85bef13762a5",
              "IPY_MODEL_cbea6346c137422bbab9b60338bcca10"
            ],
            "layout": "IPY_MODEL_6dcdd5e8e3e841f28f8b11c38cd56aa5"
          }
        },
        "c022f2ce3f0e4535a1297ef72e9a3c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbea6346c137422bbab9b60338bcca10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe79ef0b1bb4d07b4238cfc63a3323a",
            "placeholder": "​",
            "style": "IPY_MODEL_4057d2a22ed8477781f79d75f06ea1d4",
            "value": " 424/425 [52:21&lt;00:10, 10.77s/it, acc=14.3, epoch=54, loss=6.55]"
          }
        },
        "cfaf842cc40242ab8bf283a70e862b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecad3d1b6d334bf0b75caac97fd73486",
              "IPY_MODEL_e3d9c1a0a8c441ea9dc504f2e11b5a2f",
              "IPY_MODEL_8728590a8f22427dbd1f037a174f7556"
            ],
            "layout": "IPY_MODEL_974d79f1685e45129d5da7f118a55977"
          }
        },
        "d2159f15ccb74367814948d54245e270": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5a0173a85384264a420723cf0040ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc39f245b4b14a8fb2d77f9f491e54df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f0a61cd5e14b3ab2c93d941106d84a",
            "placeholder": "​",
            "style": "IPY_MODEL_493b7c0c97214ad2ae91fc43828c2833",
            "value": " 1895/1984 [54:09&lt;06:36,  4.45s/it, acc=15.9, epoch=56, loss=5.18]"
          }
        },
        "e3d9c1a0a8c441ea9dc504f2e11b5a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5a0173a85384264a420723cf0040ac4",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6e0a863916848e2b29b4dbb98fc8913",
            "value": 55
          }
        },
        "ecad3d1b6d334bf0b75caac97fd73486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17ddad575524460abeb80005deb72ee5",
            "placeholder": "​",
            "style": "IPY_MODEL_7aee607a66454c329c3518315fb380ab",
            "value": "training routine:  55%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}