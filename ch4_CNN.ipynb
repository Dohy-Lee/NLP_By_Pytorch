{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7UDh8OjJCb+FjQGnZmiLV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf3222eeacc14e08bcb387d52edd2ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53e79693ed4b4f87b5715bc5af20f05b",
              "IPY_MODEL_8c6c88c58a0b4193a3a45b0793fdbba1",
              "IPY_MODEL_0ccdf4939314484991ac985cd236ca6b"
            ],
            "layout": "IPY_MODEL_727104b2498245dd9b1ab750c81306e8"
          }
        },
        "53e79693ed4b4f87b5715bc5af20f05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c5df6e5bc54a0985f283990f40dea2",
            "placeholder": "​",
            "style": "IPY_MODEL_e2eec3a8c4944b64b0b4c262e69c703b",
            "value": "training routine: 100%"
          }
        },
        "8c6c88c58a0b4193a3a45b0793fdbba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1347e828ce0e413eaf59c303ab375187",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48792f64166e4c06add5d9313752c489",
            "value": 100
          }
        },
        "0ccdf4939314484991ac985cd236ca6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dd2223bdd184299a2a868a954ce44c5",
            "placeholder": "​",
            "style": "IPY_MODEL_1400893965304e4d939e367c80c59545",
            "value": " 100/100 [19:30&lt;00:00, 12.47s/it]"
          }
        },
        "727104b2498245dd9b1ab750c81306e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c5df6e5bc54a0985f283990f40dea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2eec3a8c4944b64b0b4c262e69c703b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1347e828ce0e413eaf59c303ab375187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48792f64166e4c06add5d9313752c489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dd2223bdd184299a2a868a954ce44c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1400893965304e4d939e367c80c59545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f6ff52ac4a409d9f15500447fb8ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89284af2586a4d4c92858d3de8230154",
              "IPY_MODEL_ce816758091a4173a911dbd417b5f750",
              "IPY_MODEL_3e3b4b1507b64bf5b25ffdee680f173f"
            ],
            "layout": "IPY_MODEL_233e8c51665a4107bdbbbac9e70c37a1"
          }
        },
        "89284af2586a4d4c92858d3de8230154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6211d7ffa349cea5706716b7496e75",
            "placeholder": "​",
            "style": "IPY_MODEL_b7eb0e45af59446f87f432ef6e518ba3",
            "value": "split=train:  98%"
          }
        },
        "ce816758091a4173a911dbd417b5f750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a8d2f6e11f46d383278ef0971eaf31",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1b61e59952847bb85a7573bc62349bb",
            "value": 59
          }
        },
        "3e3b4b1507b64bf5b25ffdee680f173f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6358209767884c2dadf577e52dbbca42",
            "placeholder": "​",
            "style": "IPY_MODEL_393c61ea80e84dbd845b363db1b54bf7",
            "value": " 59/60 [19:30&lt;00:00,  5.74it/s, acc=65, epoch=99, loss=0.757]"
          }
        },
        "233e8c51665a4107bdbbbac9e70c37a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6211d7ffa349cea5706716b7496e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7eb0e45af59446f87f432ef6e518ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a8d2f6e11f46d383278ef0971eaf31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b61e59952847bb85a7573bc62349bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6358209767884c2dadf577e52dbbca42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393c61ea80e84dbd845b363db1b54bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27e559af47a44793b196101a00e8df11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29e83f6b96584ba9a0478b98b66dde02",
              "IPY_MODEL_ad08342f1ea641669e87655154fa5413",
              "IPY_MODEL_641bc10548084ba79c00d105b6f2bed3"
            ],
            "layout": "IPY_MODEL_b0e2e78faa79458cbf2e3342ea8457d2"
          }
        },
        "29e83f6b96584ba9a0478b98b66dde02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99d7136332f4ca09fb15641a01e8b1c",
            "placeholder": "​",
            "style": "IPY_MODEL_92574e3dcb714fcf9c49dcdeb6753b7b",
            "value": "split=val:  92%"
          }
        },
        "ad08342f1ea641669e87655154fa5413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95c3a36b550d4fe99b4f1009659a538f",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a34d6536a5c4cf5b1a27fd7a8e325ab",
            "value": 11
          }
        },
        "641bc10548084ba79c00d105b6f2bed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f465d42ede43368cf00ddb5e3f8dc6",
            "placeholder": "​",
            "style": "IPY_MODEL_dce3437b5f0b4eed8bfb3c5d599d9e03",
            "value": " 11/12 [19:30&lt;00:00,  2.67it/s, acc=54.9, epoch=99, loss=2.01]"
          }
        },
        "b0e2e78faa79458cbf2e3342ea8457d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99d7136332f4ca09fb15641a01e8b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92574e3dcb714fcf9c49dcdeb6753b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95c3a36b550d4fe99b4f1009659a538f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a34d6536a5c4cf5b1a27fd7a8e325ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93f465d42ede43368cf00ddb5e3f8dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce3437b5f0b4eed8bfb3c5d599d9e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dohy-Lee/NLP_By_Pytorch/blob/main/ch4_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN(Convolution Neural Network)  \n",
        "공간상의 부분 구조를 감지하는 데 적합함.  \n",
        "소수의 가중치를 사용하여 입력 데이터 텐서를 스캔하는 방식으로 이를 수행함. 스캔하면서 부분 구조의 유무를 표현하는 출력 텐서를 만듦  \n",
        " * 1차원 합성곱 (Conv1d) : 각 타임 스텝에 특성 벡터가 있는 시계열에 잘 맞음.  \n",
        " 이 경우 시퀀스 차원을 따라 패턴을 학습할 수 있음.  \n",
        " NLP에서 합성곱 연산은 대부분 1차원임\n",
        " * 2차원 합성곱 (Conv2d) : 데이터의 두 방향을 따라 시공간 패턴을 감지. 예) 이미지의 높이와 너비 차원  \n",
        " 이미지 처리 분야에서 많이 쓰임  \n",
        " * 3차원 합성곱 (Conv3d) : 데이터의 세 방향을 따라 패턴을 감지.   \n",
        " 예) 비디오 데이터(두 차원은 이미지 프레임을 나타내고, 하나는 시간 차원은 프레임의 시퀀스)\n",
        " * 채널(Channel) : 입력의 각 포인트에 있는 특성 차원을 의미  \n",
        " 예) 이미지의 경우 픽셀마다 RGB에 해당하는 차원이 3개가 있음  \n",
        "텍스트 문서의 픽셀이 단어라면 채널 개수는 어휘 크기(이 집합이 어휘 사전을 이룸)\n",
        " * 커널 크기 : 커널 행렬의 너비. 커널 크기를 늘리면 출력의 크기가 줄어듦  \n",
        "NLP에서는 여러 단어를 보면서 언어의 패턴을 감지하는 <u>'n-그램'</u>과 비슷하다 볼 수 있음.  \n",
        "커널 크기가 작을수록, 작고 자주 등장하는 패턴을 감지. 커널 크기가 커지면 큰 패턴을 감지  \n",
        "→ 작은 커널은 상세한 특성을 출력, 큰 커널은 성긴 특성을 만듦\n",
        " * 스트라이드 : 합성공 간의 스탭 크기 제어. 높이면  출력 텐서의 크기를 의도적으로 줄여서 정보를 요약할 수 있음.  \n",
        " 스트라이드 = 커널의크기: 커널 연산이 겹치지 않음  \n",
        " 스트라이드 = 1 : 커널이 가장 많이 겹침. \n",
        " * 패딩 : 입력텐서의 (1D,2D,3D라면) 길이, (2D, 3D라면) 높이, (3D라면) 깊이차원의 앞뒤에 0을 추가하여 인공적으로 늘려줌\n",
        " → CNN이 합성곱을 더 많이 수행할 수 있으며, 출력 크기를 조절할 수 있음.\n",
        " * 다일레이션(팽창 계수) : 합성곱 커널이 입력 행렬에 적용되는 방식을 제어  \n",
        " 다일레이션을 디폴트값 1에서 2로 늘리면 입력 행렬에 적용될 때 커널의 원소 사이에 공간이 생김  \n",
        "즉, dilation이 2라면 커널 사이의 간격이 2가 되는 것이고, 커널의 크기가 (3,3)이라면 (5,5) 커널과 동일한 넓이  \n",
        "파라미터 개수를 늘리지 않고 넓은 입력 공간을 요약하는 데 유용  \n",
        "다일레이션 합성곱은 합성곱 층을 쌓을 때 매우 유용하다고 입증되었음.  \n",
        "연속된 다일레이션 합성곱은 수용장의 크기를 기하급수적으로 늘려줌.  \n",
        "*&nbsp;수용장 : 신경망이 예측을 만들기 전에 바라보는 입력 공간의 크기"
      ],
      "metadata": {
        "id": "exHQR-9rjRNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "seed = 1337\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "dxqdM1DwXDON"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "13XMA4YOjQIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7acdba-d467-4d2f-f55a-edf75cf5fa3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 10, 7])\n",
            "torch.Size([2, 16, 5])\n"
          ]
        }
      ],
      "source": [
        "# 인공 데이터와 Conv1d\n",
        "batch_size = 2\n",
        "one_hot_size = 10\n",
        "sequence_width = 7\n",
        "data = torch.randn(batch_size, one_hot_size, sequence_width) # 크기는 3차원. 벡터로 변경된 텍스트 데이터에서 만든 미니배치의 크기임.\n",
        "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=16, kernel_size=3)\n",
        "intermediate1 = conv1(data)\n",
        "print(data.size())\n",
        "print(intermediate1.size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data,'\\n')\n",
        "print(intermediate1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLFfkQ313Itv",
        "outputId": "16ac4f89-b58b-4480-f8a6-3ae0bd3bb1ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.1808, -0.0700, -0.3596, -0.9152,  0.6258,  0.0255,  0.9545],\n",
            "         [ 0.0643,  0.3612,  1.1679, -1.3499, -0.5102,  0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433,  1.3488, -0.1396,  0.2858,  0.9651, -2.0371],\n",
            "         [ 0.4931,  1.4870,  0.5910,  0.1260, -1.5627, -1.1601, -0.3348],\n",
            "         [ 0.4478, -0.8016,  1.5236,  2.5086, -0.6631, -0.2513,  1.0101],\n",
            "         [ 0.1215,  0.1584,  1.1340, -1.1539, -0.2984, -0.5075, -0.9239],\n",
            "         [ 0.5467, -1.4948, -1.2057,  0.5718, -0.5974, -0.6937,  1.6455],\n",
            "         [-0.8030,  1.3514, -0.2759, -1.5108,  2.1048,  2.7630, -1.7465],\n",
            "         [ 1.4516, -1.5103,  0.8212, -0.2115,  0.7789,  1.5333,  1.6097],\n",
            "         [-0.4032, -0.8345,  0.5978, -0.0514, -0.0646, -0.4970,  0.4658]],\n",
            "\n",
            "        [[-0.2573, -1.0673,  2.0089, -0.5370,  0.2228,  0.6971, -1.4267],\n",
            "         [ 0.9059,  0.1446,  0.2280,  2.4900, -1.2237,  1.0107,  0.5560],\n",
            "         [-1.5935, -1.2706,  0.6903, -0.1961,  0.3449, -0.3419,  0.4759],\n",
            "         [-0.7663, -0.4190, -0.4370, -1.0012, -0.4094, -1.6669, -1.3651],\n",
            "         [-0.1655,  0.9623,  0.0315, -0.7419, -0.2978,  0.0172, -0.1772],\n",
            "         [-0.1334,  0.2940,  1.3850,  0.1209,  2.5418, -0.6405, -1.9740],\n",
            "         [-0.3296,  0.0080,  0.9262, -1.8846,  0.1670,  0.4586, -1.7662],\n",
            "         [ 0.5860,  1.7510,  0.2807,  0.3110, -0.6538, -0.2450,  0.2712],\n",
            "         [ 0.0936, -0.8834,  2.2874,  0.9611, -1.5297, -0.2912,  0.1119],\n",
            "         [ 2.3143, -0.7989, -0.5643, -0.9913,  0.1700,  1.2249, -0.2345]]]) \n",
            "\n",
            "tensor([[[ 1.0278, -0.4761, -0.0755, -0.3320, -0.3411],\n",
            "         [-0.4598, -0.8531, -0.5712, -0.0884, -1.4726],\n",
            "         [ 0.0748, -0.3362,  0.0805,  0.2301, -0.0640],\n",
            "         [ 0.5059,  0.0030, -0.2405,  0.2701,  0.6335],\n",
            "         [ 0.3922,  0.8163, -0.5855, -1.2575, -0.0535],\n",
            "         [ 1.4491,  0.0309,  0.2182,  1.1591,  0.7459],\n",
            "         [ 0.1052, -0.0319,  0.4256,  0.3442,  0.0693],\n",
            "         [-0.1253, -0.3189,  1.2296,  0.8684, -0.2944],\n",
            "         [-0.5576,  1.0284, -0.0055,  0.1001,  1.8322],\n",
            "         [ 0.2295,  1.0909,  0.1720, -0.1568, -0.0043],\n",
            "         [-0.0414,  0.4882,  0.3298, -1.0940, -0.1680],\n",
            "         [-0.3271,  0.0271,  0.0220, -0.1549, -0.0526],\n",
            "         [ 1.0370,  0.3857,  0.3054,  0.2705, -0.1055],\n",
            "         [ 0.0672,  0.7960, -0.7457, -0.6970,  1.4540],\n",
            "         [-0.5188,  0.6504,  0.1532, -0.8816,  0.3643],\n",
            "         [ 0.1625, -1.7750,  1.1964,  1.2761, -1.4293]],\n",
            "\n",
            "        [[ 0.6380,  1.5767,  0.2638,  0.1284, -0.0481],\n",
            "         [-0.9966, -0.5614, -1.0460, -0.8077,  0.6883],\n",
            "         [ 0.2321, -1.5895,  0.2281,  0.0477, -0.6489],\n",
            "         [ 0.5953,  0.3102, -0.0217,  0.0064, -0.9221],\n",
            "         [-0.1821, -0.0973, -0.0724,  0.0580, -0.6031],\n",
            "         [ 0.5330, -0.1402,  1.1340, -0.2945, -0.5536],\n",
            "         [ 0.1127, -0.8181,  1.2248, -0.3373, -0.0904],\n",
            "         [ 0.8751, -0.4778, -0.9498,  0.4398, -0.4457],\n",
            "         [-0.0107,  1.0195, -0.2984,  0.5657, -0.1472],\n",
            "         [-0.6636, -0.1634, -0.5895, -0.9422, -0.7051],\n",
            "         [-0.0582, -0.4112, -0.1424, -0.6575, -0.0633],\n",
            "         [ 0.2480,  0.3943, -0.4992, -0.1111,  0.3265],\n",
            "         [-0.3547, -0.4146,  1.2767,  0.0526, -0.2173],\n",
            "         [-0.4212, -0.3204, -1.2435,  0.6063, -0.2901],\n",
            "         [-0.3421,  0.8617, -1.0138,  1.1527,  0.7759],\n",
            "         [ 1.1104,  0.6847, -0.7936,  1.5656,  0.5077]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 출력 텐서 크기를 줄이는 방법 3가지\n",
        " * 1) 합성곱 층을 더 만들어 차례로 적용 "
      ],
      "metadata": {
        "id": "mZ1uCyG8cT66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터에 반복 적용한 합성곱\n",
        "conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "\n",
        "intermediate2 = conv2(intermediate1)\n",
        "intermediate3 = conv3(intermediate2)\n",
        "\n",
        "print(intermediate2.size())\n",
        "print(intermediate3.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKGNbmDtXGTd",
        "outputId": "5af3dc17-267f-46c7-b8ec-55e3f70321fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 32, 3])\n",
            "torch.Size([2, 64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_output = intermediate3.squeeze() #squeeze : size=1인 차원을 모두 삭제한 결과 반환\n",
        "print(y_output.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7kzkgeRa57R",
        "outputId": "46fda4c3-7e2f-4210-889d-2ca226f9e95e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " * 2) 남은 값을 특성 벡터로 펼치는 방법\n",
        "  * 모든 벡터를 파이토치의 view 메서드를 사용해 하나의 벡터로 펼침\n",
        "  * 모든 정보를 유지하지만, 필요 이상으로 (혹은 적절한 계산량 이상으로) 큰 특성 벡터를 만들수도 있음\n",
        " * 3) 특성 맵 차원을 따라 평균을 계산하는 방법\n",
        "  * 수학 연산을 사용해 정보를 벡터로 요약. 수학 연산으론 산술 평균, 합산, 최댓값 고르는 등이 있지만, 산술 평균을 많이 사용함.\n",
        "  * 특성 맵 차원의 크기에 상관은 없지만, 일부 정보를 잃을 수 있음"
      ],
      "metadata": {
        "id": "DR0475to9HfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성 벡터를 줄이는 두 가지 추가 방법\n",
        "\n",
        "# 특성 벡터를 줄이는 방법 2\n",
        "print(intermediate1.view(batch_size, -1).size())\n",
        "\n",
        "# 특성 벡터를 줄이는 방법 3\n",
        "print(torch.mean(intermediate1, dim=2).size())"
      ],
      "metadata": {
        "id": "DJbiD581bbuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f87ea9-2719-46c3-cfcf-7a597cfed0b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 80])\n",
            "torch.Size([2, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN으로 성씨 분류하기"
      ],
      "metadata": {
        "id": "aQVqzwRxc5L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "AafbQb6Ccehh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 벡터 변환\n",
        "class Vocabulary(object): # 매핑을 위해 텍스트를 처리하고 어휘 사전을 만듦\n",
        "\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"): # token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
        "                                                                            # add_unk (bool): UNK 토큰을 추가할지 지정하는 플래그\n",
        "                                                                            # unk_token (str): Vocabulary에 추가할 UNK 토큰\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "        \n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token) \n",
        "        \n",
        "        \n",
        "    def to_serializable(self): # 직렬화할 수 있는 딕셔너리 반환\n",
        "        return {'token_to_idx': self._token_to_idx, \n",
        "                'add_unk': self._add_unk, \n",
        "                'unk_token': self._unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents): #직렬화된 딕셔너리에서 Vocabulary 객체를 만듦\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token): # 토큰을 기반으로 매핑 딕셔너리 업데이트\n",
        "                                # token (str): Vocabulary에 추가할 토큰\n",
        "                                # 반환값 : index (int): 토큰에 상응하는 정수\n",
        "        try:\n",
        "            index = self._token_to_idx[token]\n",
        "        except KeyError:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "    \n",
        "    def add_many(self, tokens): # 토큰 리스트를 Vocabulary에 추가\n",
        "                                # tokens (list): 문자열 토큰 리스트\n",
        "                                # 반환값 : indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token): # 토큰에 대응하는 인덱스를 추출\n",
        "                                   # token (str): 찾을 토큰 \n",
        "                                   # 반환값: index (int): 토큰에 해당하는 인덱스\n",
        "                                   # UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해) `unk_index`가 0보다 커야함\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index): # 인덱스에 해당하는 토큰을 반환\n",
        "                                   # index (int): 찾을 인덱스\n",
        "                                   # 반환값 : token (str): 인텍스에 해당하는 토큰\n",
        "\n",
        "        if index not in self._idx_to_token: # 인덱스가 Vocabulary에 없을 때 발생\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "metadata": {
        "id": "Ay2AXLa6c8pe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameVectorizer(object): # 어휘 사전을 생성하고 관리\n",
        "\n",
        "    def __init__(self, surname_vocab, nationality_vocab, max_surname_length): # surname_vocab (Vocabulary): 문자를 정수에 매핑하는 Vocabulary 객체\n",
        "                                                                              # nationality_vocab (Vocabulary): 국적을 정수에 매핑하는 Vocabulary 객체\n",
        "                                                                              # max_surname_length (int): 가장 긴 성씨 길이\n",
        "        self.surname_vocab = surname_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "        self._max_surname_length = max_surname_length\n",
        "\n",
        "    def vectorize(self, surname): # 성씨에 대한 원-핫 벡터를 만듦\n",
        "                                  # surname (str): 성씨\n",
        "                                  # 반환값 : one_hot (np.ndarray): 원-핫 벡터의 행렬\n",
        "        one_hot_matrix_size = (len(self.surname_vocab), self._max_surname_length)\n",
        "        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)\n",
        "                               \n",
        "        for position_index, character in enumerate(surname):\n",
        "            character_index = self.surname_vocab.lookup_token(character)\n",
        "            one_hot_matrix[character_index][position_index] = 1\n",
        "        \n",
        "        return one_hot_matrix\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, surname_df): # 데이터셋 데이터프레임에서 Vectorizer 객체를 만듦\n",
        "                                         # surname_df (pandas.DataFrame): 성씨 데이터셋\n",
        "                                         # 반환값 : SurnameVectorizer 객체\n",
        "\n",
        "        surname_vocab = Vocabulary(unk_token=\"@\")\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\n",
        "        max_surname_length = 0\n",
        "\n",
        "        for index, row in surname_df.iterrows():\n",
        "            max_surname_length = max(max_surname_length, len(row.surname))\n",
        "            for letter in row.surname:\n",
        "                surname_vocab.add_token(letter)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "\n",
        "        return cls(surname_vocab, nationality_vocab, max_surname_length)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\n",
        "        nationality_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "        return cls(surname_vocab=surname_vocab, nationality_vocab=nationality_vocab, \n",
        "                   max_surname_length=contents['max_surname_length'])\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable(), \n",
        "                'max_surname_length': self._max_surname_length}"
      ],
      "metadata": {
        "id": "wl-9x3nZeHGz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, surname_df, vectorizer): # surname_df (pandas.DataFrame): 데이터셋\n",
        "                                                # vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "        self.surname_df = surname_df\n",
        "        self._vectorizer = vectorizer\n",
        "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "        # 클래스 가중치\n",
        "        class_counts = surname_df.nationality.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, surname_csv): # 데이터셋을 로드하고 새로운 SurnameVectorizer 객체를 만듦\n",
        "                                                            # review_csv (str): 데이터셋의 위치\n",
        "                                                            # 반환값 : SurnameDataset의 인스턴스\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        train_surname_df = surname_df[surname_df.split=='train']\n",
        "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath): # 데이터셋을 로드하고 새로운 SurnameVectorizer 객체를 만듦. 캐시된 SurnameVectorizer 객체를 재사용할 때 사용\n",
        "                                                                                 # surname_csv (str): 데이터셋의 위치\n",
        "                                                                                 # vectorizer_filepath (str): SurnameVectorizer 객체의 저장 위치\n",
        "                                                                                 # 반환값 : SurnameDataset의 인스턴스\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(surname_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath): # 파일에서 SurnameVectorizer 객체를 로드하는 정적 메서드\n",
        "                                                   # vectorizer_filepath (str): 직렬화된 SurnameVectorizer 객체의 위치\n",
        "                                                   # 반환값 : SurnameVectorizer의 인스턴스\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath): # SurnameVectorizer 객체를 json 형태로 디스크에 저장\n",
        "                                                    # vectorizer_filepath (str): SurnameVectorizer 객체의 저장 위치\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self): # 벡터 변환 객체를 반환\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"): # 데이터프레임에 있는 열을 사용해 분할 세트를 선택\n",
        "                                        # split (str): \"train\", \"val\", \"test\" 중 하나\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index): # index (int): 데이터 포인트의 인덱스\n",
        "                                  # 반환값 : 데이터 포인트의 특성(x_surname)과 레이블(y_nationality)로 이루어진 딕셔너리\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        surname_matrix = \\\n",
        "            self._vectorizer.vectorize(row.surname)\n",
        "\n",
        "        nationality_index = \\\n",
        "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "\n",
        "        return {'x_surname': surname_matrix,\n",
        "                'y_nationality': nationality_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size): # 배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환\n",
        "                                           # batch_size (int)\n",
        "                                           # 반환값 : 배치 개수\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True, # 파이토치 DataLoader를 감싸고 있는 제너레이터 함수, 각 텐서를 지정된 장치로 이동\n",
        "                     drop_last=True, device=\"cpu\"):\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "metadata": {
        "id": "k3GYaAdoeI0f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameClassifier(nn.Module):\n",
        "    def __init__(self, initial_num_channels, num_classes, num_channels): # initial_num_channels (int): 입력 특성 벡터의 크기\n",
        "                                                                         # num_classes (int): 출력 예측 벡터의 크기\n",
        "                                                                         # num_channels (int): 신경망 전체에 사용될 채널 크기\n",
        "        super(SurnameClassifier, self).__init__()\n",
        "        \n",
        "        self.convnet = nn.Sequential( #sequential : 연속적인 선형연산을 캡슐화 해주는 래퍼 클래스. 여기선 연속된 Conv1d층을 캡슐화\n",
        "            nn.Conv1d(in_channels=initial_num_channels, \n",
        "                      out_channels=num_channels, kernel_size=3),\n",
        "            nn.ELU(), # Relu와 비슷한 비선형 함수지만 0 이하를 지수적으로 감소. 합성곱 층 사이에 쓰기 좋은 비선형 함수임.\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                      kernel_size=3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                      kernel_size=3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv1d(in_channels=num_channels, out_channels=num_channels, \n",
        "                      kernel_size=3),\n",
        "            nn.ELU()\n",
        "        )\n",
        "        self.fc = nn.Linear(num_channels, num_classes)\n",
        "\n",
        "    def forward(self, x_surname, apply_softmax=False): # 모델의 정방향 계산\n",
        "                                                       # x_surname (torch.Tensor): 입력 데이터 텐서. x_surname.shape은 (batch, initial_num_channels, max_surname_length)\n",
        "                                                       # apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그. 크로스-엔트로피 손실을 사용하려면 False로 지정\n",
        "                                                       # 반환값: 결과 텐서. tensor.shape은 (batch, num_classes)\n",
        "        features = self.convnet(x_surname).squeeze(dim=2)\n",
        "       \n",
        "        prediction_vector = self.fc(features)\n",
        "\n",
        "        if apply_softmax:\n",
        "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
        "\n",
        "        return prediction_vector"
      ],
      "metadata": {
        "id": "pu5aggKgeK5v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}"
      ],
      "metadata": {
        "id": "-l-YysBYeMlY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_train_state(args, model, train_state): # 훈련 상태를 업데이트\n",
        "                                                  # args: 메인 매개변수\n",
        "                                                  # model: 훈련할 모델\n",
        "                                                  # train_state: 훈련 상태를 담은 딕셔너리\n",
        "                                                  # 반환값: 새로운 훈련 상태\n",
        "    \n",
        "    # 적어도 한 번 모델을 저장\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # 성능이 향상되면 모델을 저장\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # 손실이 나빠지면\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # 조기 종료 단계 업데이트\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # 손실이 감소하면\n",
        "        else:\n",
        "            # 최상의 모델 저장\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # 조기 종료 단계 재설정\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # 조기 종료 여부 확인\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state"
      ],
      "metadata": {
        "id": "kr2TMFEreNrA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(y_pred, y_target):\n",
        "    y_pred_indices = y_pred.max(dim=1)[1]\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ],
      "metadata": {
        "id": "eD8D041qeO0w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Namespace(\n",
        "    # 날짜와 경로 정보\n",
        "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch4/cnn\",\n",
        "    # 모델 하이퍼파라미터\n",
        "    hidden_dim=100,\n",
        "    num_channels=256,\n",
        "    # 훈련 하이퍼파라미터\n",
        "    seed=1337,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=128,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    dropout_p=0.1,\n",
        "    # 실행 옵션\n",
        "    cuda=True,\n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    catch_keyboard_interrupt=True\n",
        ")\n",
        "\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"파일 경로: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "# CUDA 체크\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "print(\"CUDA 사용여부: {}\".format(args.cuda))\n",
        "\n",
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        \n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "        \n",
        "# 재현성을 위해 시드 설정\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# 디렉토리 처리\n",
        "handle_dirs(args.save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFZCINwvePnZ",
        "outputId": "83a80ba9-8aac-46b1-d466-32ba2ef7880e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일 경로: \n",
            "\tmodel_storage/ch4/cnn/vectorizer.json\n",
            "\tmodel_storage/ch4/cnn/model.pth\n",
            "CUDA 사용여부: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!wget https://git.io/JtaFp -O data/download.py\n",
        "!wget https://git.io/Jtabe -O data/get-all-data.sh\n",
        "!chmod 755 data/get-all-data.sh\n",
        "%cd data\n",
        "!./get-all-data.sh\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aHpc9C5eixQ",
        "outputId": "d2ea747b-c352-4056-bc72-c10ac8c1cb6d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-11 12:16:19--  https://git.io/JtaFp\n",
            "Resolving git.io (git.io)... 140.82.112.21\n",
            "Connecting to git.io (git.io)|140.82.112.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/download.py [following]\n",
            "--2022-09-11 12:16:19--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1572 (1.5K) [text/plain]\n",
            "Saving to: ‘data/download.py’\n",
            "\n",
            "data/download.py    100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-11 12:16:19 (24.9 MB/s) - ‘data/download.py’ saved [1572/1572]\n",
            "\n",
            "--2022-09-11 12:16:20--  https://git.io/Jtabe\n",
            "Resolving git.io (git.io)... 140.82.112.21\n",
            "Connecting to git.io (git.io)|140.82.112.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/get-all-data.sh [following]\n",
            "--2022-09-11 12:16:20--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/get-all-data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 507 [text/plain]\n",
            "Saving to: ‘data/get-all-data.sh’\n",
            "\n",
            "data/get-all-data.s 100%[===================>]     507  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-11 12:16:20 (27.4 MB/s) - ‘data/get-all-data.sh’ saved [507/507]\n",
            "\n",
            "/content/data\n",
            "Trying to fetch /content/data/surnames/surnames.csv\n",
            "6it [00:00, 3256.87it/s]\n",
            "Trying to fetch /content/data/surnames/surnames_with_splits.csv\n",
            "8it [00:00, 2875.52it/s]\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if args.reload_from_files:\n",
        "    # 체크포인트에서 훈련을 다시 시작\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # 데이터셋과 Vectorizer 만들기\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = SurnameClassifier(initial_num_channels=len(vectorizer.surname_vocab), \n",
        "                               num_classes=len(vectorizer.nationality_vocab),\n",
        "                               num_channels=args.num_channels)\n",
        "\n",
        "classifer = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss(weight=dataset.class_weights)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)"
      ],
      "metadata": {
        "id": "GU9GQlXbeRWR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if args.reload_from_files:\n",
        "    # 체크포인트에서 훈련을 다시 시작\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # 데이터셋과 Vectorizer 만들기\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = SurnameClassifier(initial_num_channels=len(vectorizer.surname_vocab), \n",
        "                               num_classes=len(vectorizer.nationality_vocab),\n",
        "                               num_channels=args.num_channels)\n",
        "\n",
        "classifer = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss(weight=dataset.class_weights)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                           mode='min', factor=0.5,\n",
        "                                           patience=1)\n",
        "\n",
        "train_state = make_train_state(args)"
      ],
      "metadata": {
        "id": "vDEyVU-8ef3y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
        "                               total=args.num_epochs,\n",
        "                               position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
        "                               total=dataset.get_num_batches(args.batch_size), \n",
        "                               position=1, \n",
        "                               leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
        "                             total=dataset.get_num_batches(args.batch_size), \n",
        "                             position=1, \n",
        "                             leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # 훈련 세트에 대한 순회\n",
        "\n",
        "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 훈련 과정은 5단계\n",
        "\n",
        "            # --------------------------------------\n",
        "            # 단계 1. 그레이디언트를 0으로 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 단계 2. 출력 계산\n",
        "            y_pred = classifier(batch_dict['x_surname'])\n",
        "\n",
        "            # 단계 3. 손실 계산\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 4. 손실을 사용해 그레이디언트 계산\n",
        "            loss.backward()\n",
        "\n",
        "            # 단계 5. 옵티마이저로 가중치 업데이트\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "\n",
        "            # 정확도 계산\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 바 업데이트\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # 검증 세트에 대한 순회\n",
        "\n",
        "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # 단계 1. 출력 계산\n",
        "            y_pred =  classifier(batch_dict['x_surname'])\n",
        "\n",
        "            # 단계 2. 손실 계산\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 3. 정확도 계산\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "bf3222eeacc14e08bcb387d52edd2ffa",
            "53e79693ed4b4f87b5715bc5af20f05b",
            "8c6c88c58a0b4193a3a45b0793fdbba1",
            "0ccdf4939314484991ac985cd236ca6b",
            "727104b2498245dd9b1ab750c81306e8",
            "a6c5df6e5bc54a0985f283990f40dea2",
            "e2eec3a8c4944b64b0b4c262e69c703b",
            "1347e828ce0e413eaf59c303ab375187",
            "48792f64166e4c06add5d9313752c489",
            "7dd2223bdd184299a2a868a954ce44c5",
            "1400893965304e4d939e367c80c59545",
            "28f6ff52ac4a409d9f15500447fb8ee4",
            "89284af2586a4d4c92858d3de8230154",
            "ce816758091a4173a911dbd417b5f750",
            "3e3b4b1507b64bf5b25ffdee680f173f",
            "233e8c51665a4107bdbbbac9e70c37a1",
            "fc6211d7ffa349cea5706716b7496e75",
            "b7eb0e45af59446f87f432ef6e518ba3",
            "13a8d2f6e11f46d383278ef0971eaf31",
            "e1b61e59952847bb85a7573bc62349bb",
            "6358209767884c2dadf577e52dbbca42",
            "393c61ea80e84dbd845b363db1b54bf7",
            "27e559af47a44793b196101a00e8df11",
            "29e83f6b96584ba9a0478b98b66dde02",
            "ad08342f1ea641669e87655154fa5413",
            "641bc10548084ba79c00d105b6f2bed3",
            "b0e2e78faa79458cbf2e3342ea8457d2",
            "a99d7136332f4ca09fb15641a01e8b1c",
            "92574e3dcb714fcf9c49dcdeb6753b7b",
            "95c3a36b550d4fe99b4f1009659a538f",
            "7a34d6536a5c4cf5b1a27fd7a8e325ab",
            "93f465d42ede43368cf00ddb5e3f8dc6",
            "dce3437b5f0b4eed8bfb3c5d599d9e03"
          ]
        },
        "id": "STl3epjCemcL",
        "outputId": "aba047e2-39e8-458a-ea4d-59fa014ee25d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf3222eeacc14e08bcb387d52edd2ffa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "split=train:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28f6ff52ac4a409d9f15500447fb8ee4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "split=val:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27e559af47a44793b196101a00e8df11"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # 출력 계산\n",
        "    y_pred =  classifier(batch_dict['x_surname'])\n",
        "    \n",
        "    # 손실 계산\n",
        "    loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # 정확도 계산\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ],
      "metadata": {
        "id": "Y406EcR6en8s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"테스트 손실: {};\".format(train_state['test_loss']))\n",
        "print(\"테스트 정확도: {}\".format(train_state['test_acc']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6G3ksBQepjz",
        "outputId": "b0d1a015-0349-4a8f-fb2a-141c9bd2d596"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 손실: 1.8036395013332365;\n",
            "테스트 정확도: 55.208333333333336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_nationality(surname, classifier, vectorizer): # 새로운 성씨로 국적 예측\n",
        "                                                          # surname (str): 분류할 성씨\n",
        "                                                          # classifier (SurnameClassifer): 분류기 객체\n",
        "                                                          # vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "                                                          # 반환값: 가장 가능성이 높은 국적과 확률로 구성된 딕셔너리\n",
        "    vectorized_surname = vectorizer.vectorize(surname)\n",
        "    vectorized_surname = torch.tensor(vectorized_surname).unsqueeze(0) # 새로운 데이터 텐서에 배치 차원을 추가할 때, size=1인 배치 차원을 추가\n",
        "    result = classifier(vectorized_surname, apply_softmax=True)\n",
        "\n",
        "    probability_values, indices = result.max(dim=1)\n",
        "    index = indices.item()\n",
        "\n",
        "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "    probability_value = probability_values.item()\n",
        "\n",
        "    return {'nationality': predicted_nationality, 'probability': probability_value}"
      ],
      "metadata": {
        "id": "ASEj_hXZeqcs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_surname = input(\"분류하려는 성씨를 입력하세요: \")\n",
        "classifier = classifier.cpu()\n",
        "prediction = predict_nationality(new_surname, classifier, vectorizer)\n",
        "print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
        "                                    prediction['nationality'],\n",
        "                                    prediction['probability']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJeOfYNMeroU",
        "outputId": "436e3a98-b2f2-4bc2-ef46-856f0cb2bf89"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분류하려는 성씨를 입력하세요: Kim\n",
            "Kim -> Korean (p=0.73)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_topk_nationality(surname, classifier, vectorizer, k=5): # 새로운 성씨에 대한 최상위 K개 국적을 예측\n",
        "                                                                    # surname (str): 분류하려는 성씨\n",
        "                                                                    # classifier (SurnameClassifer): 분류기 객체\n",
        "                                                                    # vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "                                                                    # k (int) : 최상위 몇 개를 보여줄 것인지\n",
        "                                                                    # 딕셔너리 리스트, 각 딕셔너리는 국적과 확률로 구성\n",
        "    vectorized_surname = vectorizer.vectorize(surname)\n",
        "    vectorized_surname = torch.tensor(vectorized_surname).unsqueeze(dim=0)\n",
        "    prediction_vector = classifier(vectorized_surname, apply_softmax=True)\n",
        "    probability_values, indices = torch.topk(prediction_vector, k=k)\n",
        "    \n",
        "    # 반환되는 크기는 (1,k)\n",
        "    probability_values = probability_values[0].detach().numpy()\n",
        "    indices = indices[0].detach().numpy()\n",
        "    \n",
        "    results = []\n",
        "    for kth_index in range(k):\n",
        "        nationality = vectorizer.nationality_vocab.lookup_index(indices[kth_index])\n",
        "        probability_value = probability_values[kth_index]\n",
        "        results.append({'nationality': nationality, \n",
        "                        'probability': probability_value})\n",
        "    return results\n",
        "\n",
        "new_surname = input(\"분류하려는 성씨를 입력하세요: \")\n",
        "\n",
        "k = int(input(\"얼마나 많은 예측을 보고 싶나요? \"))\n",
        "if k > len(vectorizer.nationality_vocab):\n",
        "    print(\"앗! 전체 국적 개수보다 큰 값을 입력했습니다. 모든 국적에 대한 예측을 반환합니다. :)\")\n",
        "    k = len(vectorizer.nationality_vocab)\n",
        "    \n",
        "predictions = predict_topk_nationality(new_surname, classifier, vectorizer, k=k)\n",
        "\n",
        "print(\"최상위 {}개 예측:\".format(k))\n",
        "print(\"===================\")\n",
        "for prediction in predictions:\n",
        "    print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
        "                                        prediction['nationality'],\n",
        "                                        prediction['probability']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2Tf62gSesZL",
        "outputId": "e81822ee-d2da-42aa-b4a8-ffec7c75293d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분류하려는 성씨를 입력하세요: Kim\n",
            "얼마나 많은 예측을 보고 싶나요? 15\n",
            "최상위 15개 예측:\n",
            "===================\n",
            "Kim -> Korean (p=0.73)\n",
            "Kim -> Chinese (p=0.14)\n",
            "Kim -> German (p=0.03)\n",
            "Kim -> English (p=0.03)\n",
            "Kim -> Scottish (p=0.03)\n",
            "Kim -> Czech (p=0.01)\n",
            "Kim -> Dutch (p=0.01)\n",
            "Kim -> Japanese (p=0.01)\n",
            "Kim -> Polish (p=0.00)\n",
            "Kim -> Russian (p=0.00)\n",
            "Kim -> Vietnamese (p=0.00)\n",
            "Kim -> Arabic (p=0.00)\n",
            "Kim -> Irish (p=0.00)\n",
            "Kim -> Spanish (p=0.00)\n",
            "Kim -> French (p=0.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가내용\n",
        "* 풀링 : 고차원 특성 맵을 저차원 특성 맵으로 요약하는 연산\n",
        " * 합성곱의 출력은 특성 맵인데, 특성 맵의 값은 입력의 일부 영역을 요약함. 합성곱 연산의 중첩되는 특징 때문에 많은 특성이 중복될 수 있음.   \n",
        " → 풀링은 고차원이고 중복 가능성이 높은 특성 맵을 저차원으로 요약함, 통계적으로 약하고 크기가 큰 특성 맵을 강하고 작은 특성 맵으로 개선할 수 있음\n",
        " * 특성 맵의 국부적인 영역에 적용하는 합(합 풀링), 평균(평균 풀링), 최댓값(최대 풀링)과 같은 산술 연산\n",
        "* 배치 정규화 : CNN을 만들 때 자주 사용되는 층.\n",
        " * CNN의 출력에 적용되어 활성화값의 평균이 0이고, 단위 분산이 되도록 만듦. \n",
        " * 파라미터 초기화에 덜 민감하게 만들고 학습률 튜닝을 단순화함\n",
        "* NiN 연결 (1x1 합성곱) : kernel_size=1인 합성곱 커널을 사용\n",
        " * 완전 연결층과 비슷 → 채널이 많은 특성 맵을 얕은 특성 맵으로 매핑하는데 유용\n",
        " * 소량의 파라미터로 비선형성을 추가로 주입할 수 있는 저렴한 방법\n",
        "* 잔차 연결(스킵 연결) : 원본 행렬에 합성곱의 출력을 더하는 방법\n",
        " * 잔차 블록의 출력 = conv (입력) + 입력"
      ],
      "metadata": {
        "id": "hNpDiUhrEvaw"
      }
    }
  ]
}